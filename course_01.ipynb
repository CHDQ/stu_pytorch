{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pytorch 学习第一节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建随机矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 4.4619e+15],\n        [8.3517e-43, 0.0000e+00, 0.0000e+00],\n        [4.4619e+15, 8.3517e-43, 4.4620e+15]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "torch.empty(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0680, 0.1212, 0.2489],\n        [0.7089, 0.1546, 0.7516],\n        [0.9396, 0.9004, 0.8264],\n        [0.9060, 0.7763, 0.7869],\n        [0.7882, 0.7859, 0.7325]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成全0矩阵,和numberpy一样的操作，可以设置数据类型，查询shape等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "x=torch.zeros(5,3,dtype=torch.long)\n",
    "x=torch.zeros(5,3).long()\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接从数据中构建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.3000, 3.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([5.3,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从已有的tensor中构建出新的tensor，会复用原有tensor的数据类型等信息。也可以明确指定tensor的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.new_ones(5,3,dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成和已有的tensor一样的shape的随机数矩阵，可以指定类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.1457,  0.9487,  0.2178],\n        [ 0.3746,  1.3100,  1.4054],\n        [-1.1810,  0.6476,  1.0142],\n        [-0.8678, -0.4694, -1.0189],\n        [-0.5754,  0.6436, -0.9185]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "x=torch.randn_like(x,dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.new_ones(5,3,dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成和已有的tensor一样的shape的随机数矩阵，可以指定类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0594,  0.1367,  0.4106],\n",
       "        [ 1.1327, -0.2244,  0.9997],\n",
       "        [ 0.8423,  1.3963,  0.1467],\n",
       "        [-0.7257,  0.6424, -1.5615],\n",
       "        [-1.2722, -0.6785, -0.7650]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn_like(x,dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取tensor的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch的操作符运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0744, 0.1148, 0.6163],\n",
       "        [0.5723, 0.8796, 0.7599],\n",
       "        [0.3265, 0.3368, 0.2739],\n",
       "        [0.0556, 0.9895, 0.1049],\n",
       "        [0.3726, 0.4788, 0.7022]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.rand(5,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2806,  0.6266,  0.8453],\n",
       "        [ 1.2708,  0.0185,  1.0680],\n",
       "        [ 1.8327,  1.7707,  1.0565],\n",
       "        [-0.0963,  0.7992, -1.3724],\n",
       "        [-0.8977, -0.0333, -0.2837]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2806,  0.6266,  0.8453],\n",
       "        [ 1.2708,  0.0185,  1.0680],\n",
       "        [ 1.8327,  1.7707,  1.0565],\n",
       "        [-0.0963,  0.7992, -1.3724],\n",
       "        [-0.8977, -0.0333, -0.2837]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用out会减少一次内存分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7049e-17, 4.5821e-41, 2.7049e-17],\n",
      "        [4.5821e-41, 6.6815e+15, 3.0739e-41],\n",
      "        [1.4013e-45, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.5821e-41],\n",
      "        [0.0000e+00, 0.0000e+00, 4.6243e-44]])\n",
      "tensor([[-1.2806,  0.6266,  0.8453],\n",
      "        [ 1.2708,  0.0185,  1.0680],\n",
      "        [ 1.8327,  1.7707,  1.0565],\n",
      "        [-0.0963,  0.7992, -1.3724],\n",
      "        [-0.8977, -0.0333, -0.2837]])\n",
      "tensor([[-1.2806,  0.6266,  0.8453],\n",
      "        [ 1.2708,  0.0185,  1.0680],\n",
      "        [ 1.8327,  1.7707,  1.0565],\n",
      "        [-0.0963,  0.7992, -1.3724],\n",
      "        [-0.8977, -0.0333, -0.2837]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2806,  0.6266,  0.8453],\n",
       "        [ 1.2708,  0.0185,  1.0680],\n",
       "        [ 1.8327,  1.7707,  1.0565],\n",
       "        [-0.0963,  0.7992, -1.3724],\n",
       "        [-0.8977, -0.0333, -0.2837]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=torch.empty(5,3)\n",
    "# torch.add(x,y,out=result)\n",
    "# result=torch.add(x,y)\n",
    "print(result)\n",
    "result=x+y\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3399,  0.7633,  1.2560],\n",
       "        [ 2.4035, -0.2059,  2.0677],\n",
       "        [ 2.6750,  3.1670,  1.2032],\n",
       "        [-0.8221,  1.4417, -2.9340],\n",
       "        [-2.1699, -0.7118, -1.0487]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4096,  1.1041, -0.5462,  0.1856],\n",
       "        [-0.1747,  0.5966, -1.2375, -0.8923],\n",
       "        [-1.5111,  0.1223, -0.4714,  0.0083],\n",
       "        [-0.3921,  0.8738,  0.1272, -0.3974]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0b8619791ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "y=x.view(16)\n",
    "z=x.view(8,-1)\n",
    "y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "如果tensor只有一个元素  可以用item直接获取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1])\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0744, 0.1148, 0.6163],\n",
       "        [0.5723, 0.8796, 0.7599],\n",
       "        [0.3265, 0.3368, 0.2739],\n",
       "        [0.0556, 0.9895, 0.1049],\n",
       "        [0.3726, 0.4788, 0.7022]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0744, 0.5723, 0.3265, 0.0556, 0.3726],\n",
       "        [0.1148, 0.8796, 0.3368, 0.9895, 0.4788],\n",
       "        [0.6163, 0.7599, 0.2739, 0.1049, 0.7022]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.transpose(-1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "tensor 转 numpy 共享一段内存，一个改另一个也改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 2., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 2., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]=2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c=torch.from_numpy(b)\n",
    "c\n",
    "c[3]=5\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch 在gpu上运行"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y=torch.ones_like(x,device=device)\n",
    "    x=x.to(device)\n",
    "    z=x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "转numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z.cpu().data.numpy()\n",
    "z.to(\"cpu\").data.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## numpy实现两层神经网络\n",
    "\n",
    "\n",
    "一个全连接的ReLu神经网络，一个隐藏层 没有bias 用x预测y 使用L2 loss\n",
    "\n",
    "- $ h=W_1x+b $\n",
    "- $ a=max(0,h) $\n",
    "- $ y_{hat}=W_2a+b_2 $\n",
    "\n",
    "计算前向神经网络 loss  和反向传播\n",
    "\n",
    "- forward pass\n",
    "- loss \n",
    "- backward pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 2., 5., 1.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 在gpu上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y=torch.ones_like(x,device=device)\n",
    "    x=x.to(device)\n",
    "    z=x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.cpu().data.numpy()\n",
    "z.to(\"cpu\").data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy实现两层神经网络\n",
    "\n",
    "\n",
    "一个全连接的ReLu神经网络，一个隐藏层 没有bias 用x预测y 使用L2 loss\n",
    "\n",
    "- $ h=W_1x+b $\n",
    "- $ a=max(0,h) $\n",
    "- $ y_{hat}=W_2a+b_2 $\n",
    "\n",
    "计算前向神经网络 loss  和反向传播\n",
    "\n",
    "- forward pass\n",
    "- loss \n",
    "- backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 43033182.26828489\n",
      "1 42894400.170374304\n",
      "2 39713920.58362867\n",
      "3 29142438.74748133\n",
      "4 16637013.515335554\n",
      "5 8115805.679354563\n",
      "6 4088069.3973143967\n",
      "7 2405466.3411081666\n",
      "8 1661257.1924571823\n",
      "9 1270179.3900668682\n",
      "10 1023634.6511177887\n",
      "11 847175.3466584745\n",
      "12 711441.6125619072\n",
      "13 603313.3421649972\n",
      "14 515367.57234898617\n",
      "15 442867.2242691413\n",
      "16 382532.0991335006\n",
      "17 331992.00286490587\n",
      "18 289386.48924529174\n",
      "19 253314.09032978656\n",
      "20 222586.2967142596\n",
      "21 196298.28212203912\n",
      "22 173647.58912220376\n",
      "23 154072.1468818813\n",
      "24 137080.49959670007\n",
      "25 122267.0407193893\n",
      "26 109305.73712633154\n",
      "27 97925.26985530682\n",
      "28 87915.22556717006\n",
      "29 79101.09577863404\n",
      "30 71295.79470424939\n",
      "31 64370.44015935834\n",
      "32 58213.47966943028\n",
      "33 52725.83172868812\n",
      "34 47824.10062409006\n",
      "35 43439.220839048874\n",
      "36 39508.10060782162\n",
      "37 35977.2466597203\n",
      "38 32801.90413824083\n",
      "39 29943.401043265858\n",
      "40 27364.306386262222\n",
      "41 25033.30068397477\n",
      "42 22923.96756060458\n",
      "43 21013.166626122005\n",
      "44 19279.470831911924\n",
      "45 17705.365929485153\n",
      "46 16275.438935035467\n",
      "47 14974.04685492651\n",
      "48 13788.510226802424\n",
      "49 12707.112005305315\n",
      "50 11720.184360426301\n",
      "51 10817.98181384199\n",
      "52 9992.70707344255\n",
      "53 9236.960918404642\n",
      "54 8544.671315917058\n",
      "55 7910.314181978902\n",
      "56 7328.160916515162\n",
      "57 6793.152547749156\n",
      "58 6301.072590323711\n",
      "59 5848.046458091374\n",
      "60 5430.727936479525\n",
      "61 5046.152664160112\n",
      "62 4691.2718069880275\n",
      "63 4363.70263920763\n",
      "64 4061.669259085521\n",
      "65 3782.535804584162\n",
      "66 3524.144246529914\n",
      "67 3284.919703843967\n",
      "68 3063.363520894135\n",
      "69 2858.1501668015817\n",
      "70 2667.8311947350157\n",
      "71 2491.157793808323\n",
      "72 2327.1453309016906\n",
      "73 2174.818149592234\n",
      "74 2033.2667573461858\n",
      "75 1901.632190229905\n",
      "76 1779.207754806745\n",
      "77 1665.2865345114462\n",
      "78 1559.226794964477\n",
      "79 1460.3985481675454\n",
      "80 1368.314276714537\n",
      "81 1282.4311776952363\n",
      "82 1202.3096101283932\n",
      "83 1127.5430155461463\n",
      "84 1057.7386121391978\n",
      "85 992.5636281782452\n",
      "86 931.6627345655907\n",
      "87 874.7425785447117\n",
      "88 821.5372226635329\n",
      "89 771.7760719068386\n",
      "90 725.2015749301603\n",
      "91 681.6113744464719\n",
      "92 640.8101471385052\n",
      "93 602.6002600287168\n",
      "94 566.7963495677518\n",
      "95 533.248901896692\n",
      "96 501.7937883529464\n",
      "97 472.2999069114158\n",
      "98 444.62850300736767\n",
      "99 418.67759861606066\n",
      "100 394.336915197938\n",
      "101 371.493763311427\n",
      "102 350.03848548301823\n",
      "103 329.88940885228976\n",
      "104 310.95505242186164\n",
      "105 293.17321877261907\n",
      "106 276.4505648849745\n",
      "107 260.72813217420764\n",
      "108 245.98370188582746\n",
      "109 232.17402698721634\n",
      "110 219.17882391418232\n",
      "111 206.95010097380487\n",
      "112 195.43254938358382\n",
      "113 184.5939429057961\n",
      "114 174.37647079561134\n",
      "115 164.7482022730469\n",
      "116 155.67763738414143\n",
      "117 147.12855562779245\n",
      "118 139.06652117802128\n",
      "119 131.4672976726884\n",
      "120 124.29896562276916\n",
      "121 117.53619603878917\n",
      "122 111.15561059324966\n",
      "123 105.13497273425715\n",
      "124 99.45176980283303\n",
      "125 94.08726522635492\n",
      "126 89.02149485190787\n",
      "127 84.23831046378892\n",
      "128 79.72323219131928\n",
      "129 75.45767360499147\n",
      "130 71.42677116663029\n",
      "131 67.61872956879321\n",
      "132 64.01998196844542\n",
      "133 60.61856825371818\n",
      "134 57.404593832219696\n",
      "135 54.36525685700681\n",
      "136 51.491033519380096\n",
      "137 48.77381192733391\n",
      "138 46.20412241342656\n",
      "139 43.77342385502885\n",
      "140 41.47429051275785\n",
      "141 39.299992875187385\n",
      "142 37.24414108579113\n",
      "143 35.29679227460159\n",
      "144 33.453525461833614\n",
      "145 31.70991390241067\n",
      "146 30.05868034260739\n",
      "147 28.495458664517642\n",
      "148 27.01534779442253\n",
      "149 25.614383889624712\n",
      "150 24.28836130897716\n",
      "151 23.032061745310166\n",
      "152 21.84185392512385\n",
      "153 20.714563589577118\n",
      "154 19.646501530508026\n",
      "155 18.635104613766735\n",
      "156 17.67723235942711\n",
      "157 16.76906041003342\n",
      "158 15.908749056606405\n",
      "159 15.093332918068672\n",
      "160 14.320478896151194\n",
      "161 13.588330705773496\n",
      "162 12.894162125908142\n",
      "163 12.236043686372193\n",
      "164 11.612173726663421\n",
      "165 11.020571554280593\n",
      "166 10.45982687886071\n",
      "167 9.928280669626195\n",
      "168 9.42393472680814\n",
      "169 8.945734773449853\n",
      "170 8.492330643273673\n",
      "171 8.062187253639019\n",
      "172 7.654352805384441\n",
      "173 7.267415080913265\n",
      "174 6.9002678013482415\n",
      "175 6.551963065149244\n",
      "176 6.221490016774191\n",
      "177 5.90804237642592\n",
      "178 5.610676025606766\n",
      "179 5.328394847757251\n",
      "180 5.0605860303723045\n",
      "181 4.806386899788676\n",
      "182 4.565180833858719\n",
      "183 4.3361869187717526\n",
      "184 4.118905512006172\n",
      "185 3.9126534106270103\n",
      "186 3.716877450032891\n",
      "187 3.5310531318167544\n",
      "188 3.3545739974090703\n",
      "189 3.1870451280641285\n",
      "190 3.0280460790478783\n",
      "191 2.8770359697948495\n",
      "192 2.73374203594431\n",
      "193 2.5976253496510977\n",
      "194 2.4684559059727214\n",
      "195 2.345693261437389\n",
      "196 2.2290839777904927\n",
      "197 2.118397717953795\n",
      "198 2.0132272787809855\n",
      "199 1.9133532536154512\n",
      "200 1.818477275078386\n",
      "201 1.7283687094791182\n",
      "202 1.6427867989921727\n",
      "203 1.561474239883045\n",
      "204 1.4842295453934773\n",
      "205 1.4108407311711555\n",
      "206 1.341149394294808\n",
      "207 1.2749242393270617\n",
      "208 1.2119915906428154\n",
      "209 1.1522310403593643\n",
      "210 1.095422963969487\n",
      "211 1.041453850867336\n",
      "212 0.990164485143744\n",
      "213 0.9414177264679764\n",
      "214 0.8951045154091963\n",
      "215 0.851094155320607\n",
      "216 0.8092640332879272\n",
      "217 0.7695125116607263\n",
      "218 0.7317285561916614\n",
      "219 0.6958103881015121\n",
      "220 0.6616879225914815\n",
      "221 0.629250624460501\n",
      "222 0.5984085344879029\n",
      "223 0.569098287024257\n",
      "224 0.5412334264198364\n",
      "225 0.5147429145901663\n",
      "226 0.48956900122457137\n",
      "227 0.46563108136977005\n",
      "228 0.4428807077889541\n",
      "229 0.421250833526829\n",
      "230 0.4006770400010256\n",
      "231 0.38111992919633036\n",
      "232 0.3625256653456998\n",
      "233 0.3448491712696664\n",
      "234 0.32803726534289007\n",
      "235 0.3120525237160041\n",
      "236 0.2968536626197342\n",
      "237 0.2824020747205255\n",
      "238 0.26866031868768353\n",
      "239 0.25558790164572276\n",
      "240 0.24315920093188245\n",
      "241 0.23134041988201526\n",
      "242 0.22010378027218122\n",
      "243 0.20942194414402937\n",
      "244 0.19925330473619024\n",
      "245 0.1895844452439261\n",
      "246 0.1803906444719699\n",
      "247 0.1716402700419381\n",
      "248 0.16331776968773093\n",
      "249 0.1554046540699399\n",
      "250 0.14787622770004885\n",
      "251 0.14071440283955938\n",
      "252 0.13390222777226804\n",
      "253 0.12742263188398156\n",
      "254 0.12125796470577957\n",
      "255 0.11539387391937664\n",
      "256 0.10981430831674845\n",
      "257 0.1045078542297089\n",
      "258 0.09946078882178198\n",
      "259 0.09465730763283298\n",
      "260 0.09008678709489307\n",
      "261 0.08573986920040756\n",
      "262 0.08160298540557973\n",
      "263 0.07766749963838639\n",
      "264 0.07392414002527642\n",
      "265 0.0703611034824229\n",
      "266 0.06697086245735288\n",
      "267 0.06374491672130755\n",
      "268 0.060675365276413096\n",
      "269 0.05775479181447862\n",
      "270 0.054975732251159815\n",
      "271 0.05233039099490008\n",
      "272 0.04981364444447163\n",
      "273 0.04741929787484318\n",
      "274 0.04513991923106672\n",
      "275 0.042970730858016615\n",
      "276 0.04090692829091479\n",
      "277 0.03894227361363588\n",
      "278 0.03707266379541891\n",
      "279 0.03529362903916244\n",
      "280 0.03360022105884512\n",
      "281 0.03198923914239335\n",
      "282 0.03045566602286876\n",
      "283 0.028995739536045218\n",
      "284 0.027605882162285694\n",
      "285 0.026283365682152525\n",
      "286 0.025024356241967957\n",
      "287 0.023827007820370033\n",
      "288 0.02268722848984373\n",
      "289 0.021601323125947862\n",
      "290 0.020567755982315212\n",
      "291 0.019584008763681635\n",
      "292 0.0186475095727848\n",
      "293 0.017756093653117963\n",
      "294 0.01690748301594039\n",
      "295 0.01609964688456175\n",
      "296 0.015330514819410246\n",
      "297 0.014598498335965153\n",
      "298 0.013901756776671308\n",
      "299 0.013238216462613391\n",
      "300 0.012606584374883888\n",
      "301 0.012005101371870127\n",
      "302 0.011432522225250638\n",
      "303 0.010887515644388321\n",
      "304 0.0103684380508038\n",
      "305 0.009874293674919578\n",
      "306 0.00940390947243318\n",
      "307 0.008955968735687835\n",
      "308 0.008529407384422018\n",
      "309 0.008123332608366094\n",
      "310 0.007736678147705835\n",
      "311 0.007368492445048223\n",
      "312 0.0070179361012034855\n",
      "313 0.006684130153034459\n",
      "314 0.0063663137602174\n",
      "315 0.006063718646319158\n",
      "316 0.005775540813859377\n",
      "317 0.005501077714685309\n",
      "318 0.005239708698352325\n",
      "319 0.004990855531907895\n",
      "320 0.004753821813431779\n",
      "321 0.004528120132217582\n",
      "322 0.004313206417110721\n",
      "323 0.004108509175001594\n",
      "324 0.003913591712909835\n",
      "325 0.003727970123412182\n",
      "326 0.003551187970066731\n",
      "327 0.003382799811057311\n",
      "328 0.0032224450937032413\n",
      "329 0.0030698570611221118\n",
      "330 0.0029244620972659723\n",
      "331 0.002786004144772013\n",
      "332 0.002654063307068553\n",
      "333 0.0025283915123995504\n",
      "334 0.0024086880948781713\n",
      "335 0.002294698879719252\n",
      "336 0.0021861186864907\n",
      "337 0.0020826876951241745\n",
      "338 0.0019841853459085356\n",
      "339 0.0018903538090459411\n",
      "340 0.0018009759116041676\n",
      "341 0.0017158427969377185\n",
      "342 0.0016347577753860888\n",
      "343 0.0015575064426211524\n",
      "344 0.0014839295415026094\n",
      "345 0.0014138555185532508\n",
      "346 0.0013470854824459105\n",
      "347 0.0012835175569622448\n",
      "348 0.0012229439552458848\n",
      "349 0.0011652243842416128\n",
      "350 0.0011102455732260761\n",
      "351 0.0010578719041468155\n",
      "352 0.0010079796765983876\n",
      "353 0.0009604468475210978\n",
      "354 0.0009151723671559728\n",
      "355 0.0008720405585605109\n",
      "356 0.0008309400893774054\n",
      "357 0.0007917843964489247\n",
      "358 0.0007544909838397003\n",
      "359 0.0007189551618082539\n",
      "360 0.0006850986930957882\n",
      "361 0.0006528467822139782\n",
      "362 0.0006221137996112968\n",
      "363 0.0005928508172673979\n",
      "364 0.000564953895314917\n",
      "365 0.0005383781940015611\n",
      "366 0.0005130543476923035\n",
      "367 0.0004889247519304625\n",
      "368 0.00046594107224920504\n",
      "369 0.0004440571816783571\n",
      "370 0.0004231885849001239\n",
      "371 0.0004033030278813407\n",
      "372 0.00038435348467219933\n",
      "373 0.00036630053608707465\n",
      "374 0.0003490954835208615\n",
      "375 0.000332704600807201\n",
      "376 0.000317082256608238\n",
      "377 0.00030219702542838437\n",
      "378 0.0002880209497464921\n",
      "379 0.00027450824646337707\n",
      "380 0.00026163033272964364\n",
      "381 0.00024935774760589024\n",
      "382 0.00023766359412536413\n",
      "383 0.00022651883465737817\n",
      "384 0.00021589839455528958\n",
      "385 0.00020578012823962223\n",
      "386 0.000196135729705324\n",
      "387 0.00018694499594291937\n",
      "388 0.00017818743235529992\n",
      "389 0.00016984051692512032\n",
      "390 0.00016188584367827033\n",
      "391 0.0001543059070744148\n",
      "392 0.0001470830194942049\n",
      "393 0.00014019862887667135\n",
      "394 0.00013363964185418052\n",
      "395 0.00012738686082488994\n",
      "396 0.00012142671331251694\n",
      "397 0.00011574672443042473\n",
      "398 0.00011033320542888449\n",
      "399 0.00010517459774286977\n",
      "400 0.00010025671634894485\n",
      "401 9.557016032204001e-05\n",
      "402 9.110387369020484e-05\n",
      "403 8.684654098405344e-05\n",
      "404 8.278904618151817e-05\n",
      "405 7.892163067811989e-05\n",
      "406 7.523594439532374e-05\n",
      "407 7.172497755096745e-05\n",
      "408 6.837693020815894e-05\n",
      "409 6.518644231319576e-05\n",
      "410 6.214401721074922e-05\n",
      "411 5.924355846033168e-05\n",
      "412 5.647953133900315e-05\n",
      "413 5.38444958142752e-05\n",
      "414 5.1332830806380075e-05\n",
      "415 4.893844632061287e-05\n",
      "416 4.665678016812035e-05\n",
      "417 4.4481275451096106e-05\n",
      "418 4.2407650255088574e-05\n",
      "419 4.043104143515703e-05\n",
      "420 3.854701556561674e-05\n",
      "421 3.675083112838027e-05\n",
      "422 3.503866552601376e-05\n",
      "423 3.3406777036250656e-05\n",
      "424 3.1851726159326264e-05\n",
      "425 3.0368541479648535e-05\n",
      "426 2.895455270314101e-05\n",
      "427 2.760678071801608e-05\n",
      "428 2.6321729652925114e-05\n",
      "429 2.5096770299326307e-05\n",
      "430 2.3929053848507068e-05\n",
      "431 2.2815911500427556e-05\n",
      "432 2.1754495356458935e-05\n",
      "433 2.074271795916771e-05\n",
      "434 1.9778221209668624e-05\n",
      "435 1.8858670142836932e-05\n",
      "436 1.7981867550846438e-05\n",
      "437 1.714611577085347e-05\n",
      "438 1.6349293087308738e-05\n",
      "439 1.558997622716503e-05\n",
      "440 1.486558737075208e-05\n",
      "441 1.4175110136510044e-05\n",
      "442 1.3516703645832794e-05\n",
      "443 1.2889027239891317e-05\n",
      "444 1.2290719286382954e-05\n",
      "445 1.1720626900544627e-05\n",
      "446 1.1176498064189395e-05\n",
      "447 1.0657758870335076e-05\n",
      "448 1.0163165789266312e-05\n",
      "449 9.691682933464977e-06\n",
      "450 9.242018633499299e-06\n",
      "451 8.813303432619832e-06\n",
      "452 8.404565245571682e-06\n",
      "453 8.014901236151491e-06\n",
      "454 7.643439903206457e-06\n",
      "455 7.289090328338783e-06\n",
      "456 6.9512541886694755e-06\n",
      "457 6.629096361905809e-06\n",
      "458 6.321905322504784e-06\n",
      "459 6.028984211856993e-06\n",
      "460 5.749713559587777e-06\n",
      "461 5.483387037810551e-06\n",
      "462 5.2294171165884974e-06\n",
      "463 4.9872694587664535e-06\n",
      "464 4.756364160964423e-06\n",
      "465 4.536155771109383e-06\n",
      "466 4.326184501577601e-06\n",
      "467 4.125984748198114e-06\n",
      "468 3.935132695282564e-06\n",
      "469 3.7530691114127583e-06\n",
      "470 3.5794400652405844e-06\n",
      "471 3.4138813881558755e-06\n",
      "472 3.255998570887242e-06\n",
      "473 3.105422867071958e-06\n",
      "474 2.961838612578653e-06\n",
      "475 2.8249176795632347e-06\n",
      "476 2.6943278084944977e-06\n",
      "477 2.5697978272519485e-06\n",
      "478 2.4510472917270664e-06\n",
      "479 2.337807730486247e-06\n",
      "480 2.2297900598566424e-06\n",
      "481 2.126785443542511e-06\n",
      "482 2.028683244999906e-06\n",
      "483 1.9350224526266903e-06\n",
      "484 1.8456739063255304e-06\n",
      "485 1.7604558393028693e-06\n",
      "486 1.679200821450911e-06\n",
      "487 1.601689827347197e-06\n",
      "488 1.5277685477743943e-06\n",
      "489 1.4572660968752278e-06\n",
      "490 1.3900380163152547e-06\n",
      "491 1.3259112225204066e-06\n",
      "492 1.2647460339299858e-06\n",
      "493 1.2064129987264154e-06\n",
      "494 1.150783871841462e-06\n",
      "495 1.0977231890082412e-06\n",
      "496 1.0471248707059684e-06\n",
      "497 9.988711246051103e-07\n",
      "498 9.528345063269355e-07\n",
      "499 9.089194254522029e-07\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "#随机创建一些训练数据\n",
    "x=np.random.randn(N,D_in)\n",
    "y=np.random.randn(N,D_out)\n",
    "w1=np.random.randn(D_in,H)\n",
    "w2=np.random.randn(H,D_out)\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    # Forward pass\n",
    "    h=x.dot(w1) # N*H\n",
    "    h_relu=np.maximum(h,0) # N*H\n",
    "    y_pred=h_relu.dot(w2)# N*D_out\n",
    "    # compute loss\n",
    "    loss =np.square(y_pred-y).sum()\n",
    "    print(i,loss)\n",
    "    # Backward pass\n",
    "    # compute the gradient\n",
    "    grad_y_pred=2.0*(y_pred-y)\n",
    "    grad_w2=h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu=grad_y_pred.dot(w2.T)\n",
    "    grad_h=grad_h_relu.copy()\n",
    "    grad_h[h<0]=0\n",
    "    grad_w1=x.T.dot(grad_h)\n",
    "    # update weights of w1 and w2\n",
    "    w1-=learning_rate*grad_w1\n",
    "    w2-=learning_rate*grad_w2\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}