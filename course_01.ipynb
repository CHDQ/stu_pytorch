{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pytorch 学习第一节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建随机矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3470e+29,  4.5820e-41, -6.3611e+29],\n",
       "        [ 4.5820e-41, -6.3472e+29,  4.5820e-41],\n",
       "        [ 6.7168e+15,  3.0739e-41, -6.5748e+29],\n",
       "        [ 4.5820e-41,  6.7174e+15,  3.0739e-41],\n",
       "        [ 6.7179e+15,  3.0739e-41,  5.5220e+15]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2282, 0.8998, 0.0200],\n",
       "        [0.4974, 0.1100, 0.0691],\n",
       "        [0.7728, 0.8181, 0.4499],\n",
       "        [0.4451, 0.2819, 0.9275],\n",
       "        [0.6880, 0.5682, 0.4771]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成全0矩阵,和numberpy一样的操作，可以设置数据类型，查询shape等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.zeros(5,3,dtype=torch.long)\n",
    "x=torch.zeros(5,3).long()\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接从数据中构建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.3000, 3.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([5.3,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从已有的tensor中构建出新的tensor，会复用原有tensor的数据类型等信息。也可以明确指定tensor的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.new_ones(5,3,dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成和已有的tensor一样的shape的随机数矩阵，可以指定类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3908, -1.2664, -0.9061],\n",
       "        [ 0.1129, -0.5327, -0.1835],\n",
       "        [-0.2790,  0.2534, -1.2388],\n",
       "        [ 0.2851,  0.0080,  0.3084],\n",
       "        [-0.3627, -0.9975, -0.4327]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn_like(x,dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.new_ones(5,3,dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成和已有的tensor一样的shape的随机数矩阵，可以指定类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0594,  0.1367,  0.4106],\n",
       "        [ 1.1327, -0.2244,  0.9997],\n",
       "        [ 0.8423,  1.3963,  0.1467],\n",
       "        [-0.7257,  0.6424, -1.5615],\n",
       "        [-1.2722, -0.6785, -0.7650]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn_like(x,dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取tensor的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch的操作符运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0744, 0.1148, 0.6163],\n",
       "        [0.5723, 0.8796, 0.7599],\n",
       "        [0.3265, 0.3368, 0.2739],\n",
       "        [0.0556, 0.9895, 0.1049],\n",
       "        [0.3726, 0.4788, 0.7022]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.rand(5,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2806,  0.6266,  0.8453],\n",
       "        [ 1.2708,  0.0185,  1.0680],\n",
       "        [ 1.8327,  1.7707,  1.0565],\n",
       "        [-0.0963,  0.7992, -1.3724],\n",
       "        [-0.8977, -0.0333, -0.2837]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2806,  0.6266,  0.8453],\n",
       "        [ 1.2708,  0.0185,  1.0680],\n",
       "        [ 1.8327,  1.7707,  1.0565],\n",
       "        [-0.0963,  0.7992, -1.3724],\n",
       "        [-0.8977, -0.0333, -0.2837]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用out会减少一次内存分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7049e-17, 4.5821e-41, 2.7049e-17],\n",
      "        [4.5821e-41, 6.6815e+15, 3.0739e-41],\n",
      "        [1.4013e-45, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.5821e-41],\n",
      "        [0.0000e+00, 0.0000e+00, 4.6243e-44]])\n",
      "tensor([[-1.2806,  0.6266,  0.8453],\n",
      "        [ 1.2708,  0.0185,  1.0680],\n",
      "        [ 1.8327,  1.7707,  1.0565],\n",
      "        [-0.0963,  0.7992, -1.3724],\n",
      "        [-0.8977, -0.0333, -0.2837]])\n",
      "tensor([[-1.2806,  0.6266,  0.8453],\n",
      "        [ 1.2708,  0.0185,  1.0680],\n",
      "        [ 1.8327,  1.7707,  1.0565],\n",
      "        [-0.0963,  0.7992, -1.3724],\n",
      "        [-0.8977, -0.0333, -0.2837]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2806,  0.6266,  0.8453],\n",
       "        [ 1.2708,  0.0185,  1.0680],\n",
       "        [ 1.8327,  1.7707,  1.0565],\n",
       "        [-0.0963,  0.7992, -1.3724],\n",
       "        [-0.8977, -0.0333, -0.2837]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=torch.empty(5,3)\n",
    "# torch.add(x,y,out=result)\n",
    "# result=torch.add(x,y)\n",
    "print(result)\n",
    "result=x+y\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3399,  0.7633,  1.2560],\n",
       "        [ 2.4035, -0.2059,  2.0677],\n",
       "        [ 2.6750,  3.1670,  1.2032],\n",
       "        [-0.8221,  1.4417, -2.9340],\n",
       "        [-2.1699, -0.7118, -1.0487]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4096,  1.1041, -0.5462,  0.1856],\n",
       "        [-0.1747,  0.5966, -1.2375, -0.8923],\n",
       "        [-1.5111,  0.1223, -0.4714,  0.0083],\n",
       "        [-0.3921,  0.8738,  0.1272, -0.3974]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-36-0b8619791ea4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mz\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mz\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "y=x.view(16)\n",
    "z=x.view(8,-1)\n",
    "y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "如果tensor只有一个元素  可以用item直接获取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1])\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0744, 0.1148, 0.6163],\n",
       "        [0.5723, 0.8796, 0.7599],\n",
       "        [0.3265, 0.3368, 0.2739],\n",
       "        [0.0556, 0.9895, 0.1049],\n",
       "        [0.3726, 0.4788, 0.7022]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0744, 0.5723, 0.3265, 0.0556, 0.3726],\n",
       "        [0.1148, 0.8796, 0.3368, 0.9895, 0.4788],\n",
       "        [0.6163, 0.7599, 0.2739, 0.1049, 0.7022]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.transpose(-1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "tensor 转 numpy 共享一段内存，一个改另一个也改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 2., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 2., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]=2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c=torch.from_numpy(b)\n",
    "c\n",
    "c[3]=5\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch 在gpu上运行"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y=torch.ones_like(x,device=device)\n",
    "    x=x.to(device)\n",
    "    z=x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "转numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z.cpu().data.numpy()\n",
    "z.to(\"cpu\").data.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## numpy实现两层神经网络\n",
    "\n",
    "\n",
    "一个全连接的ReLu神经网络，一个隐藏层 没有bias 用x预测y 使用L2 loss\n",
    "\n",
    "- $ h=W_1x+b $\n",
    "- $ a=max(0,h) $\n",
    "- $ y_{hat}=W_2a+b_2 $\n",
    "\n",
    "计算前向神经网络 loss  和反向传播\n",
    "\n",
    "- forward pass\n",
    "- loss \n",
    "- backward pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 2., 5., 1.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 在gpu上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y=torch.ones_like(x,device=device)\n",
    "    x=x.to(device)\n",
    "    z=x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.cpu().data.numpy()\n",
    "z.to(\"cpu\").data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy实现两层神经网络\n",
    "\n",
    "\n",
    "一个全连接的ReLu神经网络，一个隐藏层 没有bias 用x预测y 使用L2 loss\n",
    "\n",
    "- $ h=W_1x+b $\n",
    "- $ a=max(0,h) $\n",
    "- $ y_{hat}=W_2a+b_2 $\n",
    "\n",
    "计算前向神经网络 loss  和反向传播\n",
    "\n",
    "- forward pass\n",
    "- loss \n",
    "- backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}