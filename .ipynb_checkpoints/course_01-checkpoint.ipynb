{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pytorch 学习第一节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建随机矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7420e+06, 5.9135e-43, 3.7420e+06],\n",
       "        [5.9135e-43, 3.7420e+06, 5.9135e-43],\n",
       "        [3.7420e+06, 5.9135e-43, 3.7420e+06],\n",
       "        [5.9135e-43, 3.7420e+06, 5.9135e-43],\n",
       "        [3.7420e+06, 5.9135e-43, 3.7420e+06]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1761, 0.0541, 0.6161],\n",
       "        [0.1763, 0.1922, 0.5677],\n",
       "        [0.8803, 0.1793, 0.2465],\n",
       "        [0.3333, 0.2264, 0.8995],\n",
       "        [0.3092, 0.0076, 0.3808]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成全0矩阵,和numberpy一样的操作，可以设置数据类型，查询shape等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.zeros(5,3,dtype=torch.long)\n",
    "x=torch.zeros(5,3).long()\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接从数据中构建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.3000, 3.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([5.3,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从已有的tensor中构建出新的tensor，会复用原有tensor的数据类型等信息。也可以明确指定tensor的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.new_ones(5,3,dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成和已有的tensor一样的shape的随机数矩阵，可以指定类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5193, -0.9891, -0.0657],\n",
       "        [ 0.4388,  0.5074,  0.6841],\n",
       "        [-1.9200,  0.1718, -0.2940],\n",
       "        [-1.2046, -0.7590, -0.6666],\n",
       "        [-0.0960, -1.3504,  0.3314]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn_like(x,dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.new_ones(5,3,dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成和已有的tensor一样的shape的随机数矩阵，可以指定类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9860,  0.3050,  0.5310],\n",
       "        [-0.8327, -1.4484,  0.1253],\n",
       "        [-0.0625, -0.6005, -0.3364],\n",
       "        [ 0.7137,  1.4022, -1.4829],\n",
       "        [-0.0111,  0.1577, -0.1614]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn_like(x,dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取tensor的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch的操作符运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8681, 0.1514, 0.0186],\n",
       "        [0.4956, 0.2430, 0.9752],\n",
       "        [0.7561, 0.7188, 0.6417],\n",
       "        [0.3629, 0.8441, 0.5996],\n",
       "        [0.4832, 0.4086, 0.4283]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.rand(5,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1179,  0.4564,  0.5496],\n",
       "        [-0.3372, -1.2054,  1.1005],\n",
       "        [ 0.6936,  0.1183,  0.3053],\n",
       "        [ 1.0767,  2.2464, -0.8833],\n",
       "        [ 0.4721,  0.5663,  0.2669]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1179,  0.4564,  0.5496],\n",
       "        [-0.3372, -1.2054,  1.1005],\n",
       "        [ 0.6936,  0.1183,  0.3053],\n",
       "        [ 1.0767,  2.2464, -0.8833],\n",
       "        [ 0.4721,  0.5663,  0.2669]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用out会减少一次内存分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0102e-38, 1.0286e-38, 1.0194e-38],\n",
      "        [9.6429e-39, 9.2755e-39, 9.1837e-39],\n",
      "        [9.3674e-39, 1.0745e-38, 1.0653e-38],\n",
      "        [9.5510e-39, 1.0561e-38, 1.0194e-38],\n",
      "        [1.1112e-38, 1.0561e-38, 9.9184e-39]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1179,  0.4564,  0.5496],\n",
       "        [-0.3372, -1.2054,  1.1005],\n",
       "        [ 0.6936,  0.1183,  0.3053],\n",
       "        [ 1.0767,  2.2464, -0.8833],\n",
       "        [ 0.4721,  0.5663,  0.2669]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=torch.empty(5,3)\n",
    "# torch.add(x,y,out=result)\n",
    "# result=torch.add(x,y)\n",
    "print(result)\n",
    "result=x+y\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1179,  0.4564,  0.5496],\n",
       "        [-0.3372, -1.2054,  1.1005],\n",
       "        [ 0.6936,  0.1183,  0.3053],\n",
       "        [ 1.0767,  2.2464, -0.8833],\n",
       "        [ 0.4721,  0.5663,  0.2669]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1123, -1.5925,  0.8143, -0.4244],\n",
       "        [ 0.3216,  1.3672,  1.6378, -0.4949],\n",
       "        [ 0.7890, -1.5421,  0.1757,  1.0032],\n",
       "        [-0.8578,  0.8142,  0.4536, -2.8045]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1123, -1.5925],\n",
       "        [ 0.8143, -0.4244],\n",
       "        [ 0.3216,  1.3672],\n",
       "        [ 1.6378, -0.4949],\n",
       "        [ 0.7890, -1.5421],\n",
       "        [ 0.1757,  1.0032],\n",
       "        [-0.8578,  0.8142],\n",
       "        [ 0.4536, -2.8045]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x.view(16)\n",
    "z=x.view(8,-1)\n",
    "y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "如果tensor只有一个元素  可以用item直接获取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1])\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1123, -1.5925,  0.8143, -0.4244,  0.3216,  1.3672,  1.6378, -0.4949,\n",
       "         0.7890, -1.5421,  0.1757,  1.0032, -0.8578,  0.8142,  0.4536, -2.8045])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1123, -1.5925,  0.8143, -0.4244,  0.3216,  1.3672,  1.6378, -0.4949,\n",
       "         0.7890, -1.5421,  0.1757,  1.0032, -0.8578,  0.8142,  0.4536, -2.8045])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.transpose(-1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "tensor 转 numpy 共享一段内存，一个改另一个也改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 2., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]=2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2., 5., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.from_numpy(b)\n",
    "c\n",
    "c[3]=5\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 在gpu上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y=torch.ones_like(x,device=device)\n",
    "    x=x.to(device)\n",
    "    z=x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.cpu().data.numpy()\n",
    "z.to(\"cpu\").data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy实现两层神经网络\n",
    "\n",
    "\n",
    "一个全连接的ReLu神经网络，一个隐藏层 没有bias 用x预测y 使用L2 loss\n",
    "\n",
    "- $ h=W_1x+b $\n",
    "- $ a=max(0,h) $\n",
    "- $ y_{hat}=W_2a+b_2 $\n",
    "\n",
    "计算前向神经网络 loss  和反向传播\n",
    "\n",
    "- forward pass\n",
    "- loss \n",
    "- backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 在gpu上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y=torch.ones_like(x,device=device)\n",
    "    x=x.to(device)\n",
    "    z=x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.cpu().data.numpy()\n",
    "z.to(\"cpu\").data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy实现两层神经网络\n",
    "\n",
    "\n",
    "一个全连接的ReLu神经网络，一个隐藏层 没有bias 用x预测y 使用L2 loss\n",
    "\n",
    "- $ h=W_1x+b $\n",
    "- $ a=max(0,h) $\n",
    "- $ y_{hat}=W_2a+b_2 $\n",
    "\n",
    "计算前向神经网络 loss  和反向传播\n",
    "\n",
    "- forward pass\n",
    "- loss \n",
    "- backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28579312.51025395\n",
      "1 22420614.58127337\n",
      "2 21337159.0813146\n",
      "3 21829468.929275185\n",
      "4 21577685.22976046\n",
      "5 19349025.110639554\n",
      "6 15135841.317100951\n",
      "7 10438426.716254987\n",
      "8 6521755.324266484\n",
      "9 3914132.135315663\n",
      "10 2362283.299378777\n",
      "11 1496643.111316604\n",
      "12 1014510.1729350332\n",
      "13 738039.7384045966\n",
      "14 569574.0716774962\n",
      "15 459385.190314412\n",
      "16 381911.35997997166\n",
      "17 323883.9111525989\n",
      "18 278420.76764345577\n",
      "19 241600.73545492126\n",
      "20 211016.5143146875\n",
      "21 185245.67797877925\n",
      "22 163279.10021778606\n",
      "23 144403.4311941017\n",
      "24 128074.41986035218\n",
      "25 113881.99881587121\n",
      "26 101503.97041884199\n",
      "27 90665.57072850442\n",
      "28 81140.86325845902\n",
      "29 72747.61093247126\n",
      "30 65340.62878522998\n",
      "31 58791.327423674986\n",
      "32 52977.056501213854\n",
      "33 47812.35802938511\n",
      "34 43211.43914007026\n",
      "35 39105.44107747871\n",
      "36 35437.12830218495\n",
      "37 32151.736103844967\n",
      "38 29203.883149174228\n",
      "39 26555.929524677304\n",
      "40 24172.24571303189\n",
      "41 22024.928762412652\n",
      "42 20085.70582380781\n",
      "43 18334.08672878148\n",
      "44 16750.496823393667\n",
      "45 15316.793626015053\n",
      "46 14017.446618594642\n",
      "47 12838.801517423875\n",
      "48 11769.140165649369\n",
      "49 10796.487458380647\n",
      "50 9909.907872536893\n",
      "51 9102.632872765778\n",
      "52 8367.336699157458\n",
      "53 7696.678200720687\n",
      "54 7084.55930829213\n",
      "55 6525.482548978424\n",
      "56 6014.08833399148\n",
      "57 5546.247511662261\n",
      "58 5117.748310122637\n",
      "59 4724.9769486748655\n",
      "60 4364.667659493121\n",
      "61 4034.0525249117154\n",
      "62 3730.5525297952217\n",
      "63 3451.5752197902975\n",
      "64 3195.04011772217\n",
      "65 2959.0350288885384\n",
      "66 2741.728244598463\n",
      "67 2541.543829200241\n",
      "68 2357.0933698316267\n",
      "69 2186.9914554377547\n",
      "70 2030.0284185329062\n",
      "71 1885.140638078181\n",
      "72 1751.3494269951325\n",
      "73 1627.6726099691803\n",
      "74 1513.496690396223\n",
      "75 1407.9929391811118\n",
      "76 1310.3513457157692\n",
      "77 1219.933869312428\n",
      "78 1136.160208800105\n",
      "79 1058.512907024271\n",
      "80 986.5153656640424\n",
      "81 919.6969667869901\n",
      "82 857.7021838587445\n",
      "83 800.1284922446523\n",
      "84 746.6557965419934\n",
      "85 696.9659678953565\n",
      "86 650.7707597134972\n",
      "87 607.8067900390197\n",
      "88 567.8385939552286\n",
      "89 530.648298279757\n",
      "90 496.03262251529134\n",
      "91 463.7912320609961\n",
      "92 433.7566658318529\n",
      "93 405.77525495121154\n",
      "94 379.6871069161367\n",
      "95 355.3612634913963\n",
      "96 332.6783286101443\n",
      "97 311.51252900596586\n",
      "98 291.7627376703906\n",
      "99 273.323077235686\n",
      "100 256.11380616182237\n",
      "101 240.07506813502567\n",
      "102 225.09103416998892\n",
      "103 211.0884446575637\n",
      "104 197.99389201666983\n",
      "105 185.75142373983118\n",
      "106 174.298932694821\n",
      "107 163.58665692871483\n",
      "108 153.56137414382755\n",
      "109 144.1798529748268\n",
      "110 135.39355198025336\n",
      "111 127.1654018215054\n",
      "112 119.45691042504835\n",
      "113 112.2359357503432\n",
      "114 105.4690906301653\n",
      "115 99.12680861935154\n",
      "116 93.18034575283939\n",
      "117 87.60538228123673\n",
      "118 82.37682339808757\n",
      "119 77.4730748955165\n",
      "120 72.87113472360093\n",
      "121 68.55280286708224\n",
      "122 64.49957986432901\n",
      "123 60.69503392703902\n",
      "124 57.123158146682066\n",
      "125 53.76840734882794\n",
      "126 50.61830366397595\n",
      "127 47.658532972313495\n",
      "128 44.87773645936052\n",
      "129 42.26490020965579\n",
      "130 39.80898095131364\n",
      "131 37.50040152395534\n",
      "132 35.33112222470079\n",
      "133 33.29027580373425\n",
      "134 31.371010136043825\n",
      "135 29.565877558988966\n",
      "136 27.86771198785536\n",
      "137 26.270032415048682\n",
      "138 24.766794534298917\n",
      "139 23.35196017133546\n",
      "140 22.020307493257707\n",
      "141 20.766770933098087\n",
      "142 19.58704731485615\n",
      "143 18.47613247963982\n",
      "144 17.429855901290132\n",
      "145 16.444330153890906\n",
      "146 15.516067615955492\n",
      "147 14.641586056229585\n",
      "148 13.817614438325387\n",
      "149 13.041222378743436\n",
      "150 12.309598785335396\n",
      "151 11.6200970343182\n",
      "152 10.970257379468688\n",
      "153 10.35777282677786\n",
      "154 9.780046610129936\n",
      "155 9.235391991422164\n",
      "156 8.72175888402873\n",
      "157 8.237342710944208\n",
      "158 7.78041694620126\n",
      "159 7.349446649509618\n",
      "160 6.942867271794606\n",
      "161 6.5593034593089214\n",
      "162 6.197366747858374\n",
      "163 5.855853345257378\n",
      "164 5.533581790496214\n",
      "165 5.229454917707699\n",
      "166 4.942317539645286\n",
      "167 4.671288945203264\n",
      "168 4.415452438991049\n",
      "169 4.173874990409933\n",
      "170 3.9457700024390565\n",
      "171 3.730433173819104\n",
      "172 3.5270696347984227\n",
      "173 3.3349626071818115\n",
      "174 3.1535191542469434\n",
      "175 2.9821515168967334\n",
      "176 2.820251245614743\n",
      "177 2.6672974357255343\n",
      "178 2.5227870626433315\n",
      "179 2.386245547221505\n",
      "180 2.2572276453628755\n",
      "181 2.1353038933746786\n",
      "182 2.0200757213843645\n",
      "183 1.911169477803949\n",
      "184 1.8082306025462473\n",
      "185 1.7109290994442072\n",
      "186 1.6189504587648342\n",
      "187 1.5319958658864923\n",
      "188 1.4498157290806062\n",
      "189 1.372091225880227\n",
      "190 1.2985931766571852\n",
      "191 1.229095554830654\n",
      "192 1.163369031283485\n",
      "193 1.1012087219105278\n",
      "194 1.0424225062646526\n",
      "195 0.9868275869177753\n",
      "196 0.9342363230121683\n",
      "197 0.8844839263004494\n",
      "198 0.8374198115165811\n",
      "199 0.792894476174529\n",
      "200 0.7507691729843948\n",
      "201 0.7109109900758701\n",
      "202 0.6731982185306867\n",
      "203 0.6375238782712698\n",
      "204 0.6037591141638183\n",
      "205 0.571800994385379\n",
      "206 0.5415565532779332\n",
      "207 0.5129325268421179\n",
      "208 0.4858418815679357\n",
      "209 0.4602029928769156\n",
      "210 0.43593058818400365\n",
      "211 0.4129537875018753\n",
      "212 0.3912023278832377\n",
      "213 0.3706105410669832\n",
      "214 0.35111485214719484\n",
      "215 0.33265682551897424\n",
      "216 0.3151801230258633\n",
      "217 0.29863680042218377\n",
      "218 0.28296899391011787\n",
      "219 0.2681301595927997\n",
      "220 0.25407824090857584\n",
      "221 0.24077237142134278\n",
      "222 0.22816935956868098\n",
      "223 0.21623259814881013\n",
      "224 0.20492745083136085\n",
      "225 0.1942189634135481\n",
      "226 0.1840761358906424\n",
      "227 0.17446942579535715\n",
      "228 0.1653685670391985\n",
      "229 0.15674715718104792\n",
      "230 0.14858204869917352\n",
      "231 0.1408438660882413\n",
      "232 0.13351265430258263\n",
      "233 0.12656639371071382\n",
      "234 0.11998514104977032\n",
      "235 0.11374938033248772\n",
      "236 0.10784059886559319\n",
      "237 0.10224176187660274\n",
      "238 0.09693591438869256\n",
      "239 0.09190806612821825\n",
      "240 0.08714330082123264\n",
      "241 0.08262821286831969\n",
      "242 0.078350255556818\n",
      "243 0.07429437125907819\n",
      "244 0.0704500558771671\n",
      "245 0.06680631989403896\n",
      "246 0.06335254989400366\n",
      "247 0.06007965610131068\n",
      "248 0.05697659326886907\n",
      "249 0.05403499945930071\n",
      "250 0.05124643544026394\n",
      "251 0.04860297411583353\n",
      "252 0.04609705287480808\n",
      "253 0.04372189802462023\n",
      "254 0.04146966439177734\n",
      "255 0.03933411538268554\n",
      "256 0.0373093785221667\n",
      "257 0.03538966157428243\n",
      "258 0.03356944277227025\n",
      "259 0.031843591257461876\n",
      "260 0.030207137191083016\n",
      "261 0.028655318472647608\n",
      "262 0.027183757054077315\n",
      "263 0.02578843234093623\n",
      "264 0.024465512921386684\n",
      "265 0.02321053777334644\n",
      "266 0.02202041760481751\n",
      "267 0.02089172686542762\n",
      "268 0.01982128199210098\n",
      "269 0.0188060368621449\n",
      "270 0.017843168273444152\n",
      "271 0.01692989929404988\n",
      "272 0.016063664429898948\n",
      "273 0.01524214347125196\n",
      "274 0.014463018107400742\n",
      "275 0.013723805036925722\n",
      "276 0.013022591868840352\n",
      "277 0.012357406741830822\n",
      "278 0.011726409654613384\n",
      "279 0.011127835478392599\n",
      "280 0.010559997155112619\n",
      "281 0.01002131966214151\n",
      "282 0.009510434608856814\n",
      "283 0.009025759056106976\n",
      "284 0.008565791817539947\n",
      "285 0.008129382904643375\n",
      "286 0.007715328166089498\n",
      "287 0.007322489385391604\n",
      "288 0.006949783683305975\n",
      "289 0.006596135285185924\n",
      "290 0.006260579060959099\n",
      "291 0.005942228459027057\n",
      "292 0.005640175364093373\n",
      "293 0.005353502186877459\n",
      "294 0.005081475495872544\n",
      "295 0.00482334849830851\n",
      "296 0.004578407596542245\n",
      "297 0.004345959496284795\n",
      "298 0.004125377885188822\n",
      "299 0.003916073064802367\n",
      "300 0.003717466324042318\n",
      "301 0.003528933400643742\n",
      "302 0.0033500130494253885\n",
      "303 0.003180210879573127\n",
      "304 0.0030190533855815557\n",
      "305 0.002866102513349478\n",
      "306 0.0027209431306457524\n",
      "307 0.0025831808064181285\n",
      "308 0.0024524371415597266\n",
      "309 0.0023283221197561293\n",
      "310 0.0022105162811124094\n",
      "311 0.0020986978645330173\n",
      "312 0.001992559680325462\n",
      "313 0.0018918196259356107\n",
      "314 0.0017962142397776096\n",
      "315 0.001705459611164402\n",
      "316 0.0016192957080935339\n",
      "317 0.001537501475563295\n",
      "318 0.0014598592966618782\n",
      "319 0.00138615296632236\n",
      "320 0.0013161886012865538\n",
      "321 0.0012497663151278754\n",
      "322 0.001186719765696378\n",
      "323 0.0011268578733748891\n",
      "324 0.0010700277405293805\n",
      "325 0.0010160785007838034\n",
      "326 0.0009648606910467283\n",
      "327 0.0009162320568329897\n",
      "328 0.0008700670295064017\n",
      "329 0.0008262406452372342\n",
      "330 0.0007846251053272648\n",
      "331 0.0007451156053550199\n",
      "332 0.0007076039644302953\n",
      "333 0.0006719874998076867\n",
      "334 0.0006381692735738798\n",
      "335 0.0006060647592742178\n",
      "336 0.0005755785186780021\n",
      "337 0.0005466301437936947\n",
      "338 0.000519142861318154\n",
      "339 0.0004930436009809595\n",
      "340 0.0004682610071424991\n",
      "341 0.0004447328128566266\n",
      "342 0.0004223874215560536\n",
      "343 0.00040116866412871045\n",
      "344 0.00038102321428580826\n",
      "345 0.00036189178448682113\n",
      "346 0.0003437234329305005\n",
      "347 0.00032647188020799715\n",
      "348 0.0003100863951582982\n",
      "349 0.00029452625768138456\n",
      "350 0.0002797506387102255\n",
      "351 0.0002657181339884208\n",
      "352 0.0002523927707107168\n",
      "353 0.0002397375201146906\n",
      "354 0.0002277189816101776\n",
      "355 0.0002163051984289559\n",
      "356 0.0002054644703946899\n",
      "357 0.00019516934787424474\n",
      "358 0.000185392762305823\n",
      "359 0.00017610644902031673\n",
      "360 0.0001672865485663293\n",
      "361 0.00015890978695164788\n",
      "362 0.00015095453497162716\n",
      "363 0.00014339903336853607\n",
      "364 0.000136221957027568\n",
      "365 0.00012940546633665318\n",
      "366 0.000122931262256711\n",
      "367 0.00011678181769557867\n",
      "368 0.0001109413553940868\n",
      "369 0.00010539369742440664\n",
      "370 0.00010012393423223975\n",
      "371 9.511841365572429e-05\n",
      "372 9.036472210493236e-05\n",
      "373 8.584992642113163e-05\n",
      "374 8.156000048709626e-05\n",
      "375 7.748520839806728e-05\n",
      "376 7.361473804050451e-05\n",
      "377 6.993838186621192e-05\n",
      "378 6.644581006686494e-05\n",
      "379 6.312807814963926e-05\n",
      "380 5.99764943076962e-05\n",
      "381 5.69830278601041e-05\n",
      "382 5.413909864236613e-05\n",
      "383 5.143747358391296e-05\n",
      "384 4.8871156031533566e-05\n",
      "385 4.643325500233497e-05\n",
      "386 4.411725362548548e-05\n",
      "387 4.1917048156326954e-05\n",
      "388 3.9826807285823335e-05\n",
      "389 3.7841285804469927e-05\n",
      "390 3.595482705505649e-05\n",
      "391 3.4162731107584666e-05\n",
      "392 3.2460131667406854e-05\n",
      "393 3.084274954361213e-05\n",
      "394 2.9306038349460238e-05\n",
      "395 2.7846080807583743e-05\n",
      "396 2.645909815328442e-05\n",
      "397 2.514140615067476e-05\n",
      "398 2.3889461781426663e-05\n",
      "399 2.2700034473082378e-05\n",
      "400 2.1570321538623274e-05\n",
      "401 2.04965917303444e-05\n",
      "402 1.947646133897561e-05\n",
      "403 1.8507246338548665e-05\n",
      "404 1.7586393855930262e-05\n",
      "405 1.6711414184679633e-05\n",
      "406 1.58801371892651e-05\n",
      "407 1.5090323352786512e-05\n",
      "408 1.4339819316819702e-05\n",
      "409 1.362673912537675e-05\n",
      "410 1.294924332706108e-05\n",
      "411 1.230547608487206e-05\n",
      "412 1.1693774564995525e-05\n",
      "413 1.1112603233538499e-05\n",
      "414 1.0560345646966854e-05\n",
      "415 1.003559079501173e-05\n",
      "416 9.537000432886729e-06\n",
      "417 9.06320613492141e-06\n",
      "418 8.613015368004816e-06\n",
      "419 8.185243440608706e-06\n",
      "420 7.77874410497448e-06\n",
      "421 7.392503237111904e-06\n",
      "422 7.025467430092372e-06\n",
      "423 6.676685885939617e-06\n",
      "424 6.345273302732058e-06\n",
      "425 6.030380396779885e-06\n",
      "426 5.731163550463956e-06\n",
      "427 5.446775705172135e-06\n",
      "428 5.176525484062653e-06\n",
      "429 4.91972345118549e-06\n",
      "430 4.675671969432692e-06\n",
      "431 4.443757141193752e-06\n",
      "432 4.223369959868637e-06\n",
      "433 4.013931100411445e-06\n",
      "434 3.8149089475975394e-06\n",
      "435 3.6257666482421297e-06\n",
      "436 3.446035722620898e-06\n",
      "437 3.2752155275388405e-06\n",
      "438 3.1128861952536418e-06\n",
      "439 2.958612677350819e-06\n",
      "440 2.812004346089337e-06\n",
      "441 2.672672277355371e-06\n",
      "442 2.5402616065644195e-06\n",
      "443 2.4144217252548757e-06\n",
      "444 2.2948326275467076e-06\n",
      "445 2.1811711068388917e-06\n",
      "446 2.0731526757238865e-06\n",
      "447 1.9704905527558757e-06\n",
      "448 1.8729242153371366e-06\n",
      "449 1.7802110863189798e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 1.6920981217209628e-06\n",
      "451 1.6083429214829317e-06\n",
      "452 1.5287377414149118e-06\n",
      "453 1.4530817145863751e-06\n",
      "454 1.381174269654524e-06\n",
      "455 1.3128323295073912e-06\n",
      "456 1.2478778277674556e-06\n",
      "457 1.1861422943514726e-06\n",
      "458 1.1274684839016563e-06\n",
      "459 1.0717026781332843e-06\n",
      "460 1.0186975727440373e-06\n",
      "461 9.683196981778079e-07\n",
      "462 9.204370741071943e-07\n",
      "463 8.749259422419475e-07\n",
      "464 8.316687818167077e-07\n",
      "465 7.905541736593601e-07\n",
      "466 7.514765693114256e-07\n",
      "467 7.143339443081295e-07\n",
      "468 6.790290587361158e-07\n",
      "469 6.454722880728533e-07\n",
      "470 6.135766013680622e-07\n",
      "471 5.832594564126432e-07\n",
      "472 5.54449834108323e-07\n",
      "473 5.270609918251791e-07\n",
      "474 5.010261390594028e-07\n",
      "475 4.762787325326129e-07\n",
      "476 4.5275555994425896e-07\n",
      "477 4.303961115386086e-07\n",
      "478 4.0914261490267574e-07\n",
      "479 3.889400700302149e-07\n",
      "480 3.697366617600798e-07\n",
      "481 3.514830750930806e-07\n",
      "482 3.3413243961417633e-07\n",
      "483 3.176390080387704e-07\n",
      "484 3.019611906871405e-07\n",
      "485 2.8705836629283695e-07\n",
      "486 2.728921615827599e-07\n",
      "487 2.5942590268338544e-07\n",
      "488 2.466251674744413e-07\n",
      "489 2.3445724060768477e-07\n",
      "490 2.228906337849101e-07\n",
      "491 2.1189517673230176e-07\n",
      "492 2.0144291762322567e-07\n",
      "493 1.9150779028126444e-07\n",
      "494 1.8206544136250347e-07\n",
      "495 1.730866248800991e-07\n",
      "496 1.645512557740126e-07\n",
      "497 1.5643758028460884e-07\n",
      "498 1.487245301017752e-07\n",
      "499 1.4139213907112165e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "#随机创建一些训练数据\n",
    "x=np.random.randn(N,D_in)\n",
    "y=np.random.randn(N,D_out)\n",
    "w1=np.random.randn(D_in,H)\n",
    "w2=np.random.randn(H,D_out)\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    # Forward pass\n",
    "    h=x.dot(w1) # N*H\n",
    "    h_relu=np.maximum(h,0) # N*H\n",
    "    y_pred=h_relu.dot(w2)# N*D_out\n",
    "    # compute loss\n",
    "    loss =np.square(y_pred-y).sum()\n",
    "    print(i,loss)\n",
    "    # Backward pass\n",
    "    # compute the gradient\n",
    "    grad_y_pred=2.0*(y_pred-y)\n",
    "    grad_w2=h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu=grad_y_pred.dot(w2.T)\n",
    "    grad_h=grad_h_relu.copy()\n",
    "    grad_h[h<0]=0\n",
    "    grad_w1=x.T.dot(grad_h)\n",
    "    # update weights of w1 and w2\n",
    "    w1-=learning_rate*grad_w1\n",
    "    w2-=learning_rate*grad_w2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52320465,  0.52119698, -1.28525231, ...,  0.76363545,\n",
       "        -0.98240673, -0.08441457],\n",
       "       [ 0.09509324, -1.67261052,  0.23656502, ...,  0.58154257,\n",
       "         1.31525968,  1.10733314],\n",
       "       [ 0.16896808, -0.72011266, -0.68525172, ..., -0.36178021,\n",
       "         1.11220638, -1.1948847 ],\n",
       "       ...,\n",
       "       [ 0.81339875,  0.41331614,  0.26407216, ..., -1.67834069,\n",
       "        -0.59990498, -0.52710425],\n",
       "       [-1.02126197, -0.30900249,  0.10956126, ..., -0.39140097,\n",
       "         1.33108018, -0.32631076],\n",
       "       [ 0.88942272, -1.01865414,  1.67293314, ..., -0.4575837 ,\n",
       "         0.7635197 ,  0.43814637]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.27204473,  1.46080208,  0.53512126, -1.73743023,  1.72744291,\n",
       "        -0.61434072,  0.94744532,  1.37846565,  0.81240906, -0.35297683],\n",
       "       [ 1.17120419,  0.08776078,  0.28372777, -2.13209141, -0.97458414,\n",
       "        -0.7412262 ,  0.2966052 , -0.15376741,  0.21847448,  0.71915635],\n",
       "       [-0.29325735,  0.09869553, -0.42067055, -0.07401521, -0.89903036,\n",
       "        -0.71822045,  0.52756669,  0.23077645, -0.4394174 , -0.6219362 ],\n",
       "       [ 0.50803141, -1.43671801, -0.4717707 , -0.02750998, -0.27962741,\n",
       "         0.73656757,  1.98833357,  0.08847045, -0.25539955, -0.09774462],\n",
       "       [-1.17770913,  0.38880854,  0.31045814, -1.79024673,  0.79473069,\n",
       "        -0.05157203,  0.0852501 , -0.06350659,  0.56291763,  0.52278558],\n",
       "       [ 0.15375957, -0.02074623, -0.8677519 ,  0.83886526, -2.36220175,\n",
       "         0.68959343, -1.41541359, -1.07518504, -0.36703053,  0.73774738],\n",
       "       [-0.81864406, -1.39366608,  0.25412772, -1.50782494, -0.26447124,\n",
       "         0.24767849, -0.51934463, -0.7321175 , -1.11668616, -0.35061729],\n",
       "       [-0.02067233, -0.11371851,  1.00589976,  1.0174508 ,  0.46219236,\n",
       "         0.40321835, -0.36800844, -0.84114678, -0.20469655, -0.66655175],\n",
       "       [-2.32613695,  0.17855758,  1.58774132,  1.66080472,  0.53562237,\n",
       "        -1.50172434,  1.63244478,  1.88224597,  0.46561513,  0.04214871],\n",
       "       [-0.03519636,  2.95881554,  0.16166357, -0.64268085,  1.13526095,\n",
       "         0.57788222,  0.04077798, -1.61767464, -1.05936129, -1.23359913],\n",
       "       [ 0.36997613,  0.24206808,  1.89495222,  0.51393888, -0.31260388,\n",
       "         0.83265204, -0.06717462, -1.08887895, -0.26918177,  0.68431577],\n",
       "       [-0.15048201,  0.16529173, -0.26860014, -1.07632856,  1.34403602,\n",
       "        -0.70853723, -0.54668736, -0.39462762, -1.79020308,  0.9235226 ],\n",
       "       [-2.26864771, -0.16278553,  1.71159178,  1.36424201, -0.23147515,\n",
       "        -1.83297174,  0.72646623, -0.96368657, -2.57602828,  1.32323402],\n",
       "       [ 0.56469284, -0.59935346, -0.37112832,  1.06718853,  1.21128692,\n",
       "         0.30593089,  0.12060148,  0.67587133, -0.32362119, -1.34875621],\n",
       "       [ 0.33244345,  1.06598924,  0.56101984,  0.90765758,  1.14120283,\n",
       "        -0.63953614, -3.05811092,  0.70897875,  0.89619116,  0.47055629],\n",
       "       [ 0.95706072, -0.5033354 ,  0.47246674,  0.79483862, -0.31534415,\n",
       "        -0.36784561, -0.81596228,  0.98996105,  0.9283965 ,  0.79789951],\n",
       "       [-0.54709446, -1.37461697, -0.17920364, -0.80881398,  1.27487428,\n",
       "        -0.89884806, -0.72695761,  1.8847609 ,  0.53321211,  0.20434716],\n",
       "       [ 0.33313861, -0.7760482 , -0.08418635, -1.21681243, -0.29230084,\n",
       "        -1.61105123,  0.70928057,  2.27415932,  1.08620016, -1.2080534 ],\n",
       "       [ 0.95414111,  1.24793706, -0.51233924,  0.26583399, -0.7244071 ,\n",
       "        -0.09030801,  0.3829407 , -1.11804293,  1.18766964,  0.32121373],\n",
       "       [ 0.09009034,  0.24680891, -0.78390693,  0.09907967, -0.49055209,\n",
       "         2.29947924, -0.07484141, -0.3823909 ,  0.21731773,  0.42571695],\n",
       "       [ 0.9113901 ,  1.10908721, -0.38901533, -0.13643128, -2.25919778,\n",
       "         0.74750784, -0.51287081,  1.71645108, -0.63924251, -1.15388366],\n",
       "       [-0.45756228, -0.36370744,  0.7755306 , -0.14411211, -0.08790282,\n",
       "        -0.78394718, -0.24491234, -1.39297845,  0.36436153, -0.90585577],\n",
       "       [-0.31793689,  0.4221478 ,  0.80492747,  2.17265648, -0.17964838,\n",
       "        -0.74282025,  0.43315655, -0.71795072, -0.08030494, -1.28568149],\n",
       "       [ 0.39937121, -0.78016982, -0.72241517,  0.21152949, -0.84717843,\n",
       "        -0.36659361,  1.07878919, -1.15288095, -1.89909263,  2.99789221],\n",
       "       [-0.828095  , -0.63797746,  1.17225491,  1.02945198,  1.79007938,\n",
       "         0.1071395 , -0.05110675, -1.70568674, -0.14180437, -0.65364161],\n",
       "       [ 0.66254295,  0.23366979, -1.66467679, -1.37980876, -1.38642443,\n",
       "        -0.5822401 , -1.18818843, -0.79810071, -0.49196452, -0.34614014],\n",
       "       [-0.67012594,  0.40423944,  1.0850239 ,  1.61696114,  0.98110548,\n",
       "         1.21224628, -1.24224831, -0.50968201,  0.75100369,  0.04721492],\n",
       "       [ 1.40210841, -1.60184151,  1.89424267, -0.13228704, -0.07462591,\n",
       "         0.02781758, -0.80796464, -0.63734543, -1.6549373 ,  0.98582782],\n",
       "       [-1.06643765,  0.70461216, -0.76742009, -0.03671636, -0.67442974,\n",
       "        -1.67697699,  1.6082001 , -0.52378246,  1.60372994, -1.9780765 ],\n",
       "       [-0.05114555,  0.129037  ,  0.7927281 , -0.74777399,  0.3354286 ,\n",
       "         0.62290176, -0.12083109,  0.30548867,  0.17812321,  0.06295232],\n",
       "       [-0.41913385, -1.69912605,  0.94904467,  0.24713326,  1.32795473,\n",
       "         0.10393859, -0.68810746, -0.32559005,  0.06756613, -0.17699031],\n",
       "       [ 0.18909936, -0.57798902, -2.09189144,  0.60288866,  0.62568277,\n",
       "        -0.8310668 , -0.48295999,  0.84512206, -2.19168823, -0.52780857],\n",
       "       [-1.09970048, -1.08852273,  0.42256059,  0.86286694, -0.1925637 ,\n",
       "        -0.67485507,  2.73377952, -1.1014091 ,  1.33645774,  0.96627002],\n",
       "       [-2.7443805 ,  1.90058497,  1.91826339,  0.41221857,  0.56821925,\n",
       "         1.07910072, -0.52269753, -2.03990035,  1.34797092, -1.07393356],\n",
       "       [-0.38719927,  0.20639042, -1.10367464, -0.28724814, -1.15572765,\n",
       "         1.94322312,  1.63908843, -0.97754893,  1.62601961,  0.20114973],\n",
       "       [ 1.84610393, -0.58910947,  0.18475647,  0.45084081,  0.35481938,\n",
       "        -1.23391098,  0.50460455, -1.52419298,  1.31041091,  0.27916211],\n",
       "       [ 0.19875271,  1.02478728,  0.01336187, -1.09663386,  0.89520531,\n",
       "         0.06458787,  0.3454014 ,  0.67920586,  0.57201709, -0.09424328],\n",
       "       [-0.8090263 , -2.20942288,  0.76846229,  0.79652546, -1.14035761,\n",
       "         1.06545014, -0.21059706, -0.03916374,  0.70021381, -0.53966616],\n",
       "       [-0.27010027,  0.44752276,  1.62283897, -0.13744153,  0.24136335,\n",
       "        -0.02330921, -0.02997143,  0.4793141 , -0.3239687 ,  0.74695603],\n",
       "       [-0.5484518 , -0.0567188 ,  1.39999958, -1.7728418 , -0.68837715,\n",
       "        -0.10989251, -1.69950358, -0.52953658,  0.42219179, -0.34280535],\n",
       "       [ 1.90546172,  0.40948346, -1.38353086,  1.10543782,  0.94552344,\n",
       "        -0.25862633, -0.59303583,  0.42912655, -0.82213536, -0.35727218],\n",
       "       [ 1.37175328,  0.46115599,  0.29591301, -1.44956105,  0.72480529,\n",
       "        -0.71365878, -0.69445086, -1.27740262,  1.08179976, -1.43526771],\n",
       "       [ 0.85864426, -0.46020529, -0.87561054, -0.80990608,  0.93343225,\n",
       "        -1.06476967,  2.90475654, -1.81815122,  0.60696095,  0.50244185],\n",
       "       [-2.05113759,  0.34627055, -0.05931564, -2.04138111,  0.46952019,\n",
       "         0.77874352,  0.11117599,  0.54748231, -0.73968708, -0.37563572],\n",
       "       [-1.758419  , -1.56575894,  0.12839776,  0.04668774, -1.6488314 ,\n",
       "         1.33260122,  0.71633556, -0.8019477 , -0.59095705,  0.03902201],\n",
       "       [ 1.05131524, -0.72430678,  1.81512498, -1.09557856,  1.33484357,\n",
       "         0.38480533, -0.57851416, -1.17520346,  1.29671839, -1.02454651],\n",
       "       [ 1.03721867, -0.52816718,  2.41995446,  0.9479441 , -1.43154398,\n",
       "         0.86174764,  1.99968013, -1.38851597, -0.11573739,  0.5543546 ],\n",
       "       [ 1.9844813 ,  0.05450434,  1.4832569 , -0.19903546,  0.1872943 ,\n",
       "        -2.08587093,  0.0066501 ,  1.17467695,  0.20690384,  0.69397119],\n",
       "       [ 0.5289332 ,  0.41562293,  0.55961419,  0.0820264 , -1.549166  ,\n",
       "        -0.6722072 , -0.2491828 ,  0.42746654, -1.27003284, -0.52801629],\n",
       "       [ 0.38993671,  0.88940344, -1.39704175, -0.21865273, -1.91774204,\n",
       "         1.27933049,  1.11063241, -0.44252942,  1.43112869,  1.24211375],\n",
       "       [-0.60131334, -0.89629795, -0.96981402,  1.51936232, -1.47727799,\n",
       "        -0.15461471, -1.20982495, -0.73365562, -0.08828017, -0.52034683],\n",
       "       [ 1.39450667, -1.00022398,  1.16487204,  0.63945118, -0.34110552,\n",
       "         0.45707113, -2.14647431, -1.13398782,  1.3630611 ,  0.6208802 ],\n",
       "       [ 0.09180573, -0.00526061,  0.70467937, -0.8613436 , -0.15416402,\n",
       "        -0.6748942 ,  0.16405754, -0.16514311, -2.02600554, -1.52939239],\n",
       "       [-0.20984518,  1.67064903,  1.6057734 , -1.4259752 , -1.02954865,\n",
       "        -0.1712429 , -1.07352484, -0.06143866, -0.61102371, -1.95438537],\n",
       "       [ 0.47189032, -0.14996194,  1.81585407,  0.42219552, -0.27626091,\n",
       "        -1.00425449, -1.20564855, -1.13915644, -2.17572846,  0.37028723],\n",
       "       [-0.57405586,  0.29748062, -0.30615686, -1.20561035,  0.77479451,\n",
       "        -1.74906368, -0.83163019,  0.77884065, -1.19466799,  0.9811368 ],\n",
       "       [ 0.18259113,  0.50177996,  0.79223966, -0.70801815, -0.58715147,\n",
       "        -0.78564324,  0.35780216,  0.69060663,  0.81688348, -1.76892793],\n",
       "       [-0.85615484,  0.21884477, -1.34049569,  0.36700471,  0.11497545,\n",
       "        -2.02966211, -0.87348753, -0.98140936,  0.47672901, -0.26487385],\n",
       "       [ 0.72846095,  0.06618001, -0.27366594, -0.42623502,  1.47739509,\n",
       "         1.18317289,  0.23212291, -0.41025194,  1.11697581, -2.17988749],\n",
       "       [-0.91103263, -1.30156705,  0.64772599, -1.87962514,  1.26983744,\n",
       "        -0.20221131,  0.6970355 ,  0.81785425, -0.40047865, -0.33933394],\n",
       "       [-1.95681228,  0.34191292,  2.33675574, -0.82809285,  0.04269831,\n",
       "        -0.2904218 , -0.1167453 ,  1.02259236,  1.23533284,  0.61634291],\n",
       "       [-0.58623008,  1.03303213,  0.96693761,  0.44562993, -0.20483441,\n",
       "        -0.47616921,  0.98637543, -0.13242345, -0.31454724, -1.01059644],\n",
       "       [-0.39287492,  0.19158283,  1.75216948, -0.04339057,  2.41307743,\n",
       "        -1.07376652, -0.89252122, -2.03212384, -0.69188599,  0.54785553],\n",
       "       [ 0.65685514,  0.81558286,  0.36168008,  1.83552901,  0.72608719,\n",
       "         0.37747741,  1.74744568, -2.02142062, -0.45315891,  0.18971133]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.76459438e-06,  1.19232498e-06, -9.26506041e-08,\n",
       "        -2.09091096e-06,  4.38465711e-06, -1.73585329e-06,\n",
       "        -5.20848117e-06,  1.88083136e-06,  5.22657445e-06,\n",
       "        -1.00299889e-06],\n",
       "       [-4.97256680e-06, -3.20267830e-06,  6.40035807e-06,\n",
       "        -8.89908384e-07, -4.05791922e-06, -1.77503939e-05,\n",
       "        -8.67469661e-06, -1.51031929e-07, -2.66806558e-06,\n",
       "        -6.52322762e-06],\n",
       "       [-3.68716016e-05,  4.28886798e-06,  1.64185559e-05,\n",
       "        -2.48618859e-05,  4.55108378e-06, -3.23725544e-05,\n",
       "        -3.67970041e-05,  1.07389672e-05,  1.87057664e-05,\n",
       "        -1.55499587e-05],\n",
       "       [ 6.62148202e-06, -5.14198378e-06, -5.83567969e-06,\n",
       "         6.50224009e-06, -1.40598518e-06,  1.06644569e-05,\n",
       "         1.68984726e-05,  6.77673094e-07, -8.75501511e-06,\n",
       "         5.94533139e-06],\n",
       "       [-6.23479687e-06,  3.71828319e-06,  7.01055980e-08,\n",
       "        -4.36200604e-06,  2.63133209e-06, -1.10931442e-05,\n",
       "        -1.43394219e-05,  4.70643402e-06,  2.69855203e-06,\n",
       "        -3.48085852e-06],\n",
       "       [-2.16651231e-06,  3.56294195e-06,  5.96491989e-07,\n",
       "        -3.20980074e-06,  4.07946591e-06, -1.03233309e-06,\n",
       "        -3.09673251e-06, -2.86758879e-06,  7.70380769e-06,\n",
       "         1.60809899e-06],\n",
       "       [-2.86467929e-06, -1.31478411e-06,  2.49657890e-06,\n",
       "         3.62195402e-07, -4.16776431e-06,  5.29232902e-06,\n",
       "         1.74296621e-06,  2.65029136e-07, -2.29635144e-06,\n",
       "         3.01048175e-06],\n",
       "       [-9.11871571e-06,  4.99003877e-06,  9.19670208e-06,\n",
       "        -5.05474150e-06,  3.58358626e-06, -1.55018266e-05,\n",
       "        -1.54565270e-05,  7.09761904e-07,  5.72290686e-06,\n",
       "        -5.44339624e-06],\n",
       "       [ 1.16870617e-05, -1.13053954e-06, -6.14612442e-06,\n",
       "         6.49322412e-06, -8.03498072e-06,  8.82600716e-06,\n",
       "         6.94975119e-06,  1.04791716e-06, -1.34145568e-05,\n",
       "         3.29556034e-06],\n",
       "       [-1.38022552e-05,  6.09512463e-06,  1.19971863e-05,\n",
       "        -8.38861793e-06,  2.40286305e-06, -1.59699068e-05,\n",
       "        -1.79386069e-05,  4.31623648e-06,  1.15268956e-05,\n",
       "        -1.73721866e-06],\n",
       "       [ 1.02579650e-05, -9.86166180e-06, -1.10169846e-05,\n",
       "         1.07273676e-05, -7.63342757e-06,  2.39676206e-05,\n",
       "         2.25827727e-05, -1.60676324e-06, -1.57283059e-05,\n",
       "         7.99728026e-06],\n",
       "       [ 4.41316755e-06, -3.33943343e-07, -4.93977072e-06,\n",
       "        -2.99802949e-06, -7.71141727e-06,  1.89651655e-06,\n",
       "         2.39292049e-06, -7.34639502e-07, -5.93899088e-06,\n",
       "         1.73510880e-06],\n",
       "       [ 1.46643255e-05, -2.85815042e-06, -1.14795271e-05,\n",
       "         1.44181661e-05, -7.72372866e-06,  1.66675901e-05,\n",
       "         2.45715092e-05,  1.91181442e-06, -1.68053407e-05,\n",
       "         2.55262999e-06],\n",
       "       [-1.15807982e-05,  4.53432477e-06,  1.59270305e-05,\n",
       "        -6.03488618e-06,  8.98042763e-06, -2.38163915e-05,\n",
       "        -1.45405477e-05,  8.33345300e-06,  6.83443424e-06,\n",
       "        -1.02240811e-05],\n",
       "       [-2.24335364e-06, -8.00987191e-07,  5.07649643e-06,\n",
       "        -3.91283024e-06,  9.18931800e-07, -2.17729865e-06,\n",
       "        -2.03118445e-06, -4.43069574e-06,  5.22982513e-06,\n",
       "         2.91191832e-06],\n",
       "       [-7.71213931e-05,  3.26651909e-05,  3.53965363e-05,\n",
       "        -4.33783880e-05,  5.87543192e-05, -1.32706609e-04,\n",
       "        -1.31274127e-04,  9.03052736e-06,  7.34138001e-05,\n",
       "        -4.04600185e-05],\n",
       "       [ 2.42951677e-05, -2.01284993e-05, -8.39169070e-06,\n",
       "         3.09378957e-05, -1.90001425e-05,  3.05206054e-05,\n",
       "         4.29838917e-05, -1.28053931e-05, -3.39125177e-05,\n",
       "         1.44312753e-05],\n",
       "       [-2.85710380e-06,  3.90384289e-06,  2.28021388e-06,\n",
       "        -1.43050857e-06,  4.21688608e-06, -6.00380877e-06,\n",
       "        -6.57659744e-06,  3.16991636e-06,  6.27407265e-06,\n",
       "        -1.47014311e-06],\n",
       "       [ 8.44894562e-06, -4.29082243e-06, -9.42067631e-06,\n",
       "         7.04265581e-06, -3.12740481e-06,  1.63951119e-05,\n",
       "         1.62340732e-05, -3.37414713e-06, -8.31646204e-06,\n",
       "         6.71879461e-06],\n",
       "       [-1.00129368e-05,  7.21187921e-06,  1.67630756e-05,\n",
       "        -7.37619940e-07,  6.50604677e-06, -1.75312100e-05,\n",
       "        -1.29395472e-05,  6.09942591e-06,  6.80277661e-06,\n",
       "        -4.88660910e-06],\n",
       "       [ 4.40557293e-06,  6.97252870e-07, -8.58306444e-07,\n",
       "         4.92597490e-06,  7.51331835e-06,  5.68885820e-06,\n",
       "         3.38598838e-06,  4.27142952e-07,  1.80857706e-06,\n",
       "        -1.21914172e-06],\n",
       "       [ 5.52802256e-06, -6.54301434e-07, -5.17442095e-06,\n",
       "         1.44781512e-06, -1.39308972e-06,  4.73801691e-06,\n",
       "         4.00581708e-06, -2.38358198e-06, -9.62839806e-07,\n",
       "         1.61334962e-06],\n",
       "       [ 2.68700658e-05, -9.20508217e-06, -1.85762596e-05,\n",
       "         1.01767627e-05, -1.73028797e-05,  2.13285262e-05,\n",
       "         2.81130268e-05, -2.67850909e-06, -1.87846744e-05,\n",
       "         7.04877109e-06],\n",
       "       [-4.84011561e-06,  6.15628341e-07,  5.02182279e-06,\n",
       "        -6.01399219e-06,  1.68582654e-06, -4.47393459e-07,\n",
       "        -5.56612702e-06, -1.52030253e-07,  6.09750878e-06,\n",
       "         2.91936768e-06],\n",
       "       [ 1.89922057e-06,  1.35091123e-06, -1.88870312e-06,\n",
       "        -2.41134989e-07, -2.16027272e-06, -6.86598264e-07,\n",
       "        -3.57498880e-07,  5.68668927e-07, -3.18284829e-06,\n",
       "        -7.39479074e-07],\n",
       "       [-8.78361352e-06, -9.92300247e-07,  2.36862416e-06,\n",
       "        -9.14666793e-06,  8.93114902e-07, -7.03594981e-06,\n",
       "        -1.20148355e-05, -1.30398283e-06,  9.33268323e-06,\n",
       "        -8.70196562e-08],\n",
       "       [ 1.11876301e-06,  3.35779716e-06, -4.33491041e-07,\n",
       "         2.54007177e-06,  4.23015762e-06, -4.90642368e-06,\n",
       "        -2.98066536e-06,  1.20131890e-06,  1.29478396e-06,\n",
       "        -4.19172311e-06],\n",
       "       [-1.31637761e-06, -1.16350144e-06,  1.43514383e-07,\n",
       "        -9.03376393e-07, -2.81242092e-06, -2.40452129e-06,\n",
       "        -7.72123133e-07, -1.92111920e-07, -2.55977306e-06,\n",
       "        -6.91500334e-07],\n",
       "       [ 2.41530147e-05, -7.87082924e-06, -1.54417110e-05,\n",
       "         1.59333623e-05, -9.14930924e-06,  2.90148687e-05,\n",
       "         3.39136722e-05, -2.34840631e-07, -2.16458066e-05,\n",
       "         4.34921828e-06],\n",
       "       [-1.00332408e-05,  4.95820479e-06,  7.33503046e-06,\n",
       "         2.61122637e-07, -2.57345668e-07, -1.51432753e-05,\n",
       "        -1.09657496e-05,  8.94646587e-06, -6.54780325e-07,\n",
       "        -3.63840853e-06],\n",
       "       [ 4.15134476e-06, -1.16313112e-06, -3.04790679e-06,\n",
       "         2.33937245e-07, -1.70399290e-06,  1.20351118e-05,\n",
       "         1.16470452e-05, -2.46899952e-06, -1.45292401e-06,\n",
       "         4.55240817e-06],\n",
       "       [ 2.19832342e-05, -6.62115692e-06, -1.47518829e-05,\n",
       "         1.36979833e-05,  1.20556695e-06,  3.86887167e-05,\n",
       "         3.67782061e-05, -3.43970022e-06, -8.73431349e-06,\n",
       "         8.18976543e-06],\n",
       "       [-1.22257301e-06,  1.49805986e-06, -6.64398392e-07,\n",
       "        -2.61551013e-06,  2.10075677e-06, -9.47997449e-07,\n",
       "        -4.34351695e-06, -1.86602685e-06,  5.13114430e-06,\n",
       "         9.15199262e-08],\n",
       "       [-1.22245194e-07,  3.08577421e-07,  1.52846522e-06,\n",
       "        -4.14150626e-06,  2.52509195e-06,  3.21187493e-06,\n",
       "         5.75787667e-07, -1.67215437e-06,  2.79687088e-06,\n",
       "         1.16137950e-06],\n",
       "       [-5.51082212e-06,  1.31660158e-05,  2.63948792e-06,\n",
       "        -1.07661261e-05,  1.70994743e-05, -1.98605059e-05,\n",
       "        -2.56796249e-05,  4.31411258e-06,  2.52868796e-05,\n",
       "         6.54971222e-07],\n",
       "       [ 1.12171949e-05, -4.15526219e-06, -1.10857285e-05,\n",
       "         1.18537384e-05, -5.51108556e-06,  1.77651864e-05,\n",
       "         1.75860431e-05,  2.03373189e-07, -1.26535538e-05,\n",
       "         3.30319587e-06],\n",
       "       [-1.17498280e-05,  5.59425669e-07,  5.03039994e-06,\n",
       "        -9.53579894e-06, -5.31207949e-07, -5.89813967e-06,\n",
       "        -1.20333626e-05, -3.75648504e-06,  8.10605445e-06,\n",
       "         2.95650753e-06],\n",
       "       [-3.17255117e-06,  1.53785169e-06,  2.35562209e-06,\n",
       "        -2.52541608e-06,  3.92115310e-06, -4.41441666e-06,\n",
       "        -6.15243228e-06, -6.00596111e-07,  5.51583269e-06,\n",
       "        -4.56114827e-07],\n",
       "       [-1.10808308e-05,  6.83321380e-06,  9.19295137e-06,\n",
       "        -9.11413913e-06, -9.18271868e-07, -1.47414562e-05,\n",
       "        -1.52280994e-05,  3.30901197e-06,  7.86631082e-06,\n",
       "        -5.99230900e-07],\n",
       "       [ 2.59240227e-05, -1.48948796e-05, -2.23057496e-05,\n",
       "         1.60183396e-05, -2.64141468e-05,  3.65173267e-05,\n",
       "         3.88284411e-05, -3.46241465e-06, -2.93816056e-05,\n",
       "         1.11676628e-05],\n",
       "       [ 1.61345599e-06,  2.09264185e-06, -1.44653822e-06,\n",
       "         1.54529829e-06, -1.72482297e-06,  4.67556570e-07,\n",
       "        -6.28786543e-07,  4.65697517e-06, -2.57667895e-06,\n",
       "        -7.83542748e-07],\n",
       "       [-3.41602891e-05,  9.03264269e-06,  2.20788382e-05,\n",
       "        -2.26786969e-05,  3.44091822e-05, -4.31468477e-05,\n",
       "        -3.78699359e-05,  1.46284765e-06,  5.06634046e-05,\n",
       "        -1.85251385e-05],\n",
       "       [-3.08782607e-06,  5.41490799e-06,  4.68304697e-06,\n",
       "         4.45827383e-07,  1.33074652e-06, -4.76457948e-06,\n",
       "        -1.54513234e-06,  3.22468383e-06, -2.08237322e-06,\n",
       "        -2.81548187e-06],\n",
       "       [-5.78544134e-06,  2.08401923e-06,  9.69037434e-06,\n",
       "        -2.68310449e-06,  3.17197996e-06, -8.77487612e-06,\n",
       "        -8.68422523e-06, -1.10617240e-06,  6.78078953e-06,\n",
       "        -2.11455787e-06],\n",
       "       [ 2.84442321e-06, -2.44011658e-06, -3.74593590e-06,\n",
       "         1.39366542e-06, -1.20908895e-06,  9.82259461e-06,\n",
       "         4.88901671e-06, -1.06098261e-06, -9.21704425e-07,\n",
       "         3.02505213e-06],\n",
       "       [ 1.03140958e-05, -3.11495716e-07, -3.75019751e-06,\n",
       "         4.98303103e-06, -4.58251301e-06,  9.51416209e-06,\n",
       "         1.28420942e-05, -1.36018961e-06, -8.13816858e-06,\n",
       "         2.64488771e-06],\n",
       "       [ 3.36272053e-06, -8.25451036e-07, -2.06637162e-06,\n",
       "         1.24614864e-06, -3.69147244e-06,  2.30199871e-06,\n",
       "         1.52037808e-06, -3.04358839e-06, -4.78491807e-06,\n",
       "         3.00955797e-06],\n",
       "       [-5.74023628e-06,  5.65268416e-07,  3.55326266e-06,\n",
       "        -7.05816257e-06,  4.07708873e-06, -6.30677201e-06,\n",
       "        -7.27184333e-06, -3.12735685e-06,  1.10314057e-05,\n",
       "        -9.03235127e-07],\n",
       "       [ 3.18800516e-05, -1.12397215e-05, -2.01963784e-05,\n",
       "         2.08720977e-05, -1.38235878e-05,  4.00514039e-05,\n",
       "         3.18923231e-05, -1.40284422e-05, -2.57362579e-05,\n",
       "         1.19688279e-05],\n",
       "       [-1.17635668e-05,  4.95300913e-06,  1.04710181e-05,\n",
       "        -1.53128523e-05,  9.02952485e-06, -1.13314506e-05,\n",
       "        -1.79806182e-05, -1.96347111e-06,  1.71940124e-05,\n",
       "        -4.50721281e-06],\n",
       "       [ 7.38501245e-06, -4.66881030e-06, -3.02273073e-06,\n",
       "         6.23423577e-06, -1.37240025e-05,  1.21789508e-05,\n",
       "         1.23872578e-05,  1.73501425e-07, -1.49688980e-05,\n",
       "         6.56779685e-06],\n",
       "       [-1.28543978e-05,  5.69085129e-06,  8.19906174e-06,\n",
       "        -8.64134184e-06,  4.87834723e-06, -1.67256676e-05,\n",
       "        -1.58593357e-05, -5.76345834e-07,  9.81252020e-06,\n",
       "        -5.19512054e-06],\n",
       "       [ 4.71849646e-06, -6.94707589e-09, -4.05893891e-06,\n",
       "         4.10077408e-06, -5.71541314e-06, -1.25362079e-06,\n",
       "         2.10123470e-06,  5.07171806e-06, -6.26652596e-06,\n",
       "        -3.22632147e-06],\n",
       "       [-7.87861580e-06,  5.92737371e-06,  8.32465568e-06,\n",
       "        -1.48026728e-05,  4.77814048e-06, -2.91517569e-06,\n",
       "        -1.13921298e-05, -1.13636742e-08,  1.21727014e-05,\n",
       "         2.56233159e-06],\n",
       "       [-2.38813491e-06,  3.57736944e-06,  9.37190464e-07,\n",
       "        -5.25913315e-06,  1.64846896e-06, -2.94393753e-06,\n",
       "        -3.94200669e-06, -7.42353871e-07,  5.58439343e-06,\n",
       "        -8.59126925e-08],\n",
       "       [ 3.89714474e-06, -8.89879344e-08, -8.06522573e-06,\n",
       "         5.78394109e-06,  4.49713727e-06,  6.49198060e-06,\n",
       "         5.02854912e-06, -2.20879913e-06,  1.64121738e-06,\n",
       "         2.17928766e-06],\n",
       "       [-5.38899117e-06, -1.46783839e-06,  6.88797517e-06,\n",
       "        -1.01845338e-05,  6.44034014e-07, -6.13143143e-06,\n",
       "        -8.67684173e-06, -4.46914212e-06,  6.47492908e-06,\n",
       "        -2.67849331e-07],\n",
       "       [ 7.58006455e-06, -6.19587537e-06, -4.05057830e-06,\n",
       "         3.03833724e-06, -5.44955420e-06,  1.04015371e-05,\n",
       "         1.23740223e-05, -1.37047825e-06, -8.16767272e-06,\n",
       "         3.83499892e-06],\n",
       "       [-4.27650083e-06,  3.14581490e-06,  1.79446762e-06,\n",
       "        -1.54030941e-06,  3.69587884e-06, -5.92526240e-06,\n",
       "        -7.56261047e-06, -9.13622952e-07,  4.72877884e-06,\n",
       "        -2.33236769e-06],\n",
       "       [ 1.33975912e-05, -6.00217514e-06, -7.82780521e-06,\n",
       "         1.10737014e-05, -4.47898814e-06,  1.19010287e-05,\n",
       "         1.59952614e-05, -9.73120975e-07, -1.46586960e-05,\n",
       "         9.92622283e-07],\n",
       "       [ 4.03892826e-06, -7.31542485e-07, -3.59144467e-06,\n",
       "         1.05792704e-06, -3.40458379e-06,  2.18505608e-06,\n",
       "         2.54317290e-06, -2.73076560e-06, -2.72593503e-06,\n",
       "         7.05250492e-07],\n",
       "       [ 1.16558271e-05, -2.06326422e-06, -9.34665796e-06,\n",
       "         5.16164981e-06, -3.63403524e-06,  1.96913551e-05,\n",
       "         1.79788811e-05, -1.50630460e-06, -8.21479650e-06,\n",
       "         6.03919436e-06],\n",
       "       [-7.51677089e-06,  1.19758050e-06,  5.67404540e-06,\n",
       "        -1.10166006e-06,  6.84494322e-06, -7.16643138e-06,\n",
       "        -9.98752664e-06,  2.46541345e-06,  6.73254482e-06,\n",
       "        -4.91269926e-06],\n",
       "       [ 2.17357661e-05, -9.41969343e-06, -8.69988817e-06,\n",
       "         2.48981043e-05, -1.57463436e-05,  2.92754578e-05,\n",
       "         3.95933779e-05,  5.65921244e-06, -3.77582856e-05,\n",
       "         4.47433264e-07]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=x.dot(w1)\n",
    "h_relu=np.maximum(h,0)\n",
    "y_pred=h_relu.dot(w2)\n",
    "y_pred-y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy 转 pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31729386.0\n",
      "1 26089402.0\n",
      "2 22358552.0\n",
      "3 18223514.0\n",
      "4 13506519.0\n",
      "5 9237244.0\n",
      "6 5958962.5\n",
      "7 3793543.0\n",
      "8 2452616.25\n",
      "9 1654215.0\n",
      "10 1172020.125\n",
      "11 872923.5625\n",
      "12 677975.9375\n",
      "13 544473.5\n",
      "14 448240.28125\n",
      "15 375902.3125\n",
      "16 319460.3125\n",
      "17 274257.9375\n",
      "18 237279.03125\n",
      "19 206554.375\n",
      "20 180727.890625\n",
      "21 158809.203125\n",
      "22 140069.5625\n",
      "23 123991.390625\n",
      "24 110091.015625\n",
      "25 98007.65625\n",
      "26 87472.078125\n",
      "27 78257.0625\n",
      "28 70168.7421875\n",
      "29 63044.25390625\n",
      "30 56760.85546875\n",
      "31 51194.734375\n",
      "32 46255.3984375\n",
      "33 41861.0546875\n",
      "34 37946.8125\n",
      "35 34450.89453125\n",
      "36 31323.662109375\n",
      "37 28516.080078125\n",
      "38 25993.49609375\n",
      "39 23722.365234375\n",
      "40 21673.7734375\n",
      "41 19823.46484375\n",
      "42 18150.0703125\n",
      "43 16634.146484375\n",
      "44 15260.2255859375\n",
      "45 14012.6416015625\n",
      "46 12878.4765625\n",
      "47 11846.44921875\n",
      "48 10905.12109375\n",
      "49 10046.2294921875\n",
      "50 9262.3828125\n",
      "51 8545.6181640625\n",
      "52 7890.517578125\n",
      "53 7291.13818359375\n",
      "54 6741.6728515625\n",
      "55 6236.95751953125\n",
      "56 5773.66357421875\n",
      "57 5347.94677734375\n",
      "58 4956.4072265625\n",
      "59 4596.0712890625\n",
      "60 4264.27734375\n",
      "61 3958.539306640625\n",
      "62 3676.54638671875\n",
      "63 3416.24609375\n",
      "64 3175.866455078125\n",
      "65 2953.8388671875\n",
      "66 2748.8564453125\n",
      "67 2559.3193359375\n",
      "68 2383.8623046875\n",
      "69 2221.330078125\n",
      "70 2070.72607421875\n",
      "71 1931.061279296875\n",
      "72 1801.5540771484375\n",
      "73 1681.3594970703125\n",
      "74 1569.793701171875\n",
      "75 1466.1376953125\n",
      "76 1369.73046875\n",
      "77 1280.085205078125\n",
      "78 1196.734375\n",
      "79 1119.15185546875\n",
      "80 1046.9197998046875\n",
      "81 979.6690673828125\n",
      "82 917.018798828125\n",
      "83 858.6145629882812\n",
      "84 804.153076171875\n",
      "85 753.3419799804688\n",
      "86 705.9407348632812\n",
      "87 661.7049560546875\n",
      "88 620.4345092773438\n",
      "89 581.8522338867188\n",
      "90 545.806396484375\n",
      "91 512.1107177734375\n",
      "92 480.6236572265625\n",
      "93 451.174072265625\n",
      "94 423.6359558105469\n",
      "95 397.8650817871094\n",
      "96 373.75537109375\n",
      "97 351.1761779785156\n",
      "98 330.0399169921875\n",
      "99 310.28924560546875\n",
      "100 291.7885437011719\n",
      "101 274.4538269042969\n",
      "102 258.1927490234375\n",
      "103 242.93841552734375\n",
      "104 228.62559509277344\n",
      "105 215.1993865966797\n",
      "106 202.59719848632812\n",
      "107 190.76544189453125\n",
      "108 179.65711975097656\n",
      "109 169.23001098632812\n",
      "110 159.42994689941406\n",
      "111 150.221435546875\n",
      "112 141.57119750976562\n",
      "113 133.43955993652344\n",
      "114 125.79450988769531\n",
      "115 118.60165405273438\n",
      "116 111.83993530273438\n",
      "117 105.47982025146484\n",
      "118 99.49671173095703\n",
      "119 93.86432647705078\n",
      "120 88.56468200683594\n",
      "121 83.5736083984375\n",
      "122 78.87621307373047\n",
      "123 74.45390319824219\n",
      "124 70.28678131103516\n",
      "125 66.36328125\n",
      "126 62.66537094116211\n",
      "127 59.18293762207031\n",
      "128 55.906524658203125\n",
      "129 52.81638717651367\n",
      "130 49.90315246582031\n",
      "131 47.157039642333984\n",
      "132 44.566829681396484\n",
      "133 42.12539291381836\n",
      "134 39.82054901123047\n",
      "135 37.64623260498047\n",
      "136 35.59496307373047\n",
      "137 33.659889221191406\n",
      "138 31.832447052001953\n",
      "139 30.106611251831055\n",
      "140 28.478322982788086\n",
      "141 26.940574645996094\n",
      "142 25.487743377685547\n",
      "143 24.117040634155273\n",
      "144 22.821914672851562\n",
      "145 21.597652435302734\n",
      "146 20.441753387451172\n",
      "147 19.34964370727539\n",
      "148 18.316925048828125\n",
      "149 17.340314865112305\n",
      "150 16.418231964111328\n",
      "151 15.547225952148438\n",
      "152 14.72316837310791\n",
      "153 13.943115234375\n",
      "154 13.206409454345703\n",
      "155 12.5094633102417\n",
      "156 11.849993705749512\n",
      "157 11.226431846618652\n",
      "158 10.63703727722168\n",
      "159 10.078726768493652\n",
      "160 9.5502347946167\n",
      "161 9.050686836242676\n",
      "162 8.577972412109375\n",
      "163 8.130095481872559\n",
      "164 7.706325054168701\n",
      "165 7.305849075317383\n",
      "166 6.925868511199951\n",
      "167 6.566244602203369\n",
      "168 6.225827217102051\n",
      "169 5.903741359710693\n",
      "170 5.598843097686768\n",
      "171 5.3097615242004395\n",
      "172 5.035885810852051\n",
      "173 4.77652645111084\n",
      "174 4.530689716339111\n",
      "175 4.297809600830078\n",
      "176 4.077402591705322\n",
      "177 3.8682868480682373\n",
      "178 3.6704745292663574\n",
      "179 3.482670307159424\n",
      "180 3.30460262298584\n",
      "181 3.1359732151031494\n",
      "182 2.9762425422668457\n",
      "183 2.824645519256592\n",
      "184 2.6809301376342773\n",
      "185 2.544724464416504\n",
      "186 2.4157025814056396\n",
      "187 2.293051242828369\n",
      "188 2.1769962310791016\n",
      "189 2.0668177604675293\n",
      "190 1.9623326063156128\n",
      "191 1.863324761390686\n",
      "192 1.7693727016448975\n",
      "193 1.680132508277893\n",
      "194 1.5956205129623413\n",
      "195 1.5153248310089111\n",
      "196 1.439107894897461\n",
      "197 1.3669737577438354\n",
      "198 1.298399567604065\n",
      "199 1.233341097831726\n",
      "200 1.1716793775558472\n",
      "201 1.1130095720291138\n",
      "202 1.057447910308838\n",
      "203 1.0046427249908447\n",
      "204 0.9545345306396484\n",
      "205 0.9069727659225464\n",
      "206 0.8617221713066101\n",
      "207 0.8189263939857483\n",
      "208 0.7782204151153564\n",
      "209 0.7395861148834229\n",
      "210 0.7027761936187744\n",
      "211 0.667967677116394\n",
      "212 0.6348457932472229\n",
      "213 0.6034027338027954\n",
      "214 0.5735957622528076\n",
      "215 0.5452682971954346\n",
      "216 0.5182348489761353\n",
      "217 0.4927537441253662\n",
      "218 0.4683968126773834\n",
      "219 0.4453602433204651\n",
      "220 0.42343974113464355\n",
      "221 0.40260085463523865\n",
      "222 0.3828127384185791\n",
      "223 0.3640645742416382\n",
      "224 0.3461591601371765\n",
      "225 0.3291691839694977\n",
      "226 0.3129979372024536\n",
      "227 0.29776617884635925\n",
      "228 0.2830367088317871\n",
      "229 0.2692295014858246\n",
      "230 0.25605514645576477\n",
      "231 0.24354201555252075\n",
      "232 0.2316356897354126\n",
      "233 0.2203417420387268\n",
      "234 0.20960070192813873\n",
      "235 0.19937662780284882\n",
      "236 0.18963107466697693\n",
      "237 0.18042521178722382\n",
      "238 0.17160993814468384\n",
      "239 0.1632777750492096\n",
      "240 0.15536443889141083\n",
      "241 0.14779984951019287\n",
      "242 0.1406055986881256\n",
      "243 0.13382162153720856\n",
      "244 0.12734642624855042\n",
      "245 0.12118060886859894\n",
      "246 0.11532709747552872\n",
      "247 0.10972297191619873\n",
      "248 0.10441416501998901\n",
      "249 0.09938070923089981\n",
      "250 0.09458132088184357\n",
      "251 0.09001173079013824\n",
      "252 0.0856432318687439\n",
      "253 0.08151803910732269\n",
      "254 0.07757281512022018\n",
      "255 0.07384256273508072\n",
      "256 0.07031489163637161\n",
      "257 0.06693004816770554\n",
      "258 0.06371282041072845\n",
      "259 0.0606582909822464\n",
      "260 0.05772363394498825\n",
      "261 0.05494622141122818\n",
      "262 0.05232790857553482\n",
      "263 0.04981940984725952\n",
      "264 0.0474344827234745\n",
      "265 0.04516944661736488\n",
      "266 0.043016090989112854\n",
      "267 0.04096625745296478\n",
      "268 0.03900497406721115\n",
      "269 0.037134695798158646\n",
      "270 0.035381417721509933\n",
      "271 0.033664483577013016\n",
      "272 0.03206503391265869\n",
      "273 0.03054412640631199\n",
      "274 0.029074275866150856\n",
      "275 0.02770012803375721\n",
      "276 0.026378339156508446\n",
      "277 0.02512500435113907\n",
      "278 0.023944465443491936\n",
      "279 0.022806255146861076\n",
      "280 0.021732373163104057\n",
      "281 0.02069438435137272\n",
      "282 0.019708292558789253\n",
      "283 0.01878075860440731\n",
      "284 0.01789787784218788\n",
      "285 0.017050690948963165\n",
      "286 0.01624869555234909\n",
      "287 0.015489719808101654\n",
      "288 0.014766229316592216\n",
      "289 0.014072573743760586\n",
      "290 0.013418426737189293\n",
      "291 0.012793943285942078\n",
      "292 0.012202288955450058\n",
      "293 0.011626793071627617\n",
      "294 0.011097070761024952\n",
      "295 0.010577376000583172\n",
      "296 0.010084878653287888\n",
      "297 0.009614306502044201\n",
      "298 0.009173886850476265\n",
      "299 0.008747761137783527\n",
      "300 0.008344732224941254\n",
      "301 0.00795782171189785\n",
      "302 0.0075933788903057575\n",
      "303 0.007248002104461193\n",
      "304 0.00692318519577384\n",
      "305 0.006608040537685156\n",
      "306 0.0063097202219069\n",
      "307 0.006026326213032007\n",
      "308 0.005746491719037294\n",
      "309 0.005491219460964203\n",
      "310 0.005247793160378933\n",
      "311 0.00501642981544137\n",
      "312 0.004795446991920471\n",
      "313 0.004585601855069399\n",
      "314 0.004380922764539719\n",
      "315 0.004185027908533812\n",
      "316 0.004004759714007378\n",
      "317 0.003830946749076247\n",
      "318 0.0036602469626814127\n",
      "319 0.0035053601022809744\n",
      "320 0.0033595936838537455\n",
      "321 0.0032121515832841396\n",
      "322 0.003074903739616275\n",
      "323 0.002939857542514801\n",
      "324 0.002821432426571846\n",
      "325 0.0027050436474382877\n",
      "326 0.0025932644493877888\n",
      "327 0.0024838706012815237\n",
      "328 0.0023839850910007954\n",
      "329 0.0022861722391098738\n",
      "330 0.0021899736020714045\n",
      "331 0.0021020001731812954\n",
      "332 0.0020165250170975924\n",
      "333 0.0019339502323418856\n",
      "334 0.0018601244082674384\n",
      "335 0.001786140608601272\n",
      "336 0.001713704434223473\n",
      "337 0.0016476336168125272\n",
      "338 0.001581469550728798\n",
      "339 0.00152221554890275\n",
      "340 0.0014640019508078694\n",
      "341 0.0014074906939640641\n",
      "342 0.001357167144306004\n",
      "343 0.0013035926967859268\n",
      "344 0.0012552848784253001\n",
      "345 0.0012103175977244973\n",
      "346 0.0011665192432701588\n",
      "347 0.0011215228587388992\n",
      "348 0.0010812890250235796\n",
      "349 0.0010420525213703513\n",
      "350 0.0010047374526038766\n",
      "351 0.0009698368376120925\n",
      "352 0.0009348465828225017\n",
      "353 0.0009035118273459375\n",
      "354 0.0008706770022399724\n",
      "355 0.0008415697375312448\n",
      "356 0.0008125648600980639\n",
      "357 0.0007848066743463278\n",
      "358 0.0007591127650812268\n",
      "359 0.0007338543655350804\n",
      "360 0.0007106417906470597\n",
      "361 0.0006879758439026773\n",
      "362 0.0006649044225923717\n",
      "363 0.0006435810355469584\n",
      "364 0.0006231472943909466\n",
      "365 0.0006028390489518642\n",
      "366 0.0005843253456987441\n",
      "367 0.0005658389418385923\n",
      "368 0.0005479283863678575\n",
      "369 0.0005304566584527493\n",
      "370 0.0005155784310773015\n",
      "371 0.0005000907112844288\n",
      "372 0.00048371986486017704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 0.0004700603021774441\n",
      "374 0.0004566347342915833\n",
      "375 0.0004445340600796044\n",
      "376 0.00043106265366077423\n",
      "377 0.0004177372029516846\n",
      "378 0.00040589598938822746\n",
      "379 0.0003945239004679024\n",
      "380 0.0003827534965239465\n",
      "381 0.00037271439214237034\n",
      "382 0.00036148616345599294\n",
      "383 0.0003526358923409134\n",
      "384 0.0003432707744650543\n",
      "385 0.0003335977380629629\n",
      "386 0.00032477531931363046\n",
      "387 0.00031677016522735357\n",
      "388 0.00030927907209843397\n",
      "389 0.00030110491206869483\n",
      "390 0.0002927040040958673\n",
      "391 0.000284792942693457\n",
      "392 0.0002781504299491644\n",
      "393 0.000271289813099429\n",
      "394 0.00026382715441286564\n",
      "395 0.0002570915094111115\n",
      "396 0.00025200785603374243\n",
      "397 0.0002452072221785784\n",
      "398 0.00023888176656328142\n",
      "399 0.00023371257702820003\n",
      "400 0.00022760062711313367\n",
      "401 0.00022270024055615067\n",
      "402 0.00021732448658440262\n",
      "403 0.00021257113257888705\n",
      "404 0.0002075422089546919\n",
      "405 0.00020255778508726507\n",
      "406 0.00019837325089611113\n",
      "407 0.00019330988288857043\n",
      "408 0.0001886343234218657\n",
      "409 0.00018497479322832078\n",
      "410 0.00018048669153358787\n",
      "411 0.00017634457617532462\n",
      "412 0.00017250105156563222\n",
      "413 0.00016908731777220964\n",
      "414 0.0001653465733397752\n",
      "415 0.0001625903241802007\n",
      "416 0.0001589931343914941\n",
      "417 0.0001558118819957599\n",
      "418 0.00015248454292304814\n",
      "419 0.00014951394405215979\n",
      "420 0.00014626885240431875\n",
      "421 0.00014341082714963704\n",
      "422 0.00014086814189795405\n",
      "423 0.00013798823056276888\n",
      "424 0.00013494666200131178\n",
      "425 0.0001327783684246242\n",
      "426 0.00013000669423490763\n",
      "427 0.00012788892490789294\n",
      "428 0.0001252058136742562\n",
      "429 0.00012305898417253047\n",
      "430 0.00012084329500794411\n",
      "431 0.00011843876563943923\n",
      "432 0.00011640635784715414\n",
      "433 0.00011394869943615049\n",
      "434 0.00011211641685804352\n",
      "435 0.00010993581236107275\n",
      "436 0.00010798763833008707\n",
      "437 0.00010620004468364641\n",
      "438 0.00010427806410007179\n",
      "439 0.00010223920980934054\n",
      "440 0.00010030256817117333\n",
      "441 9.854693780653179e-05\n",
      "442 9.735591447679326e-05\n",
      "443 9.56475778366439e-05\n",
      "444 9.397030953550711e-05\n",
      "445 9.264599066227674e-05\n",
      "446 9.083468466997147e-05\n",
      "447 8.96892452146858e-05\n",
      "448 8.810700091999024e-05\n",
      "449 8.647242066217586e-05\n",
      "450 8.537348912796006e-05\n",
      "451 8.405166590819135e-05\n",
      "452 8.280892507173121e-05\n",
      "453 8.151335350703448e-05\n",
      "454 8.039593376452103e-05\n",
      "455 7.905282836873084e-05\n",
      "456 7.770238153170794e-05\n",
      "457 7.652760541532189e-05\n",
      "458 7.562025712104514e-05\n",
      "459 7.48086313251406e-05\n",
      "460 7.363787153735757e-05\n",
      "461 7.263828592840582e-05\n",
      "462 7.150699093472213e-05\n",
      "463 7.045117672532797e-05\n",
      "464 6.918823055457324e-05\n",
      "465 6.783480057492852e-05\n",
      "466 6.711800233460963e-05\n",
      "467 6.649292481597513e-05\n",
      "468 6.560939800692722e-05\n",
      "469 6.456190749304369e-05\n",
      "470 6.371519702952355e-05\n",
      "471 6.257502536755055e-05\n",
      "472 6.1872458900325e-05\n",
      "473 6.10932765994221e-05\n",
      "474 6.0068603488616645e-05\n",
      "475 5.9383033658377826e-05\n",
      "476 5.862369653186761e-05\n",
      "477 5.814894393552095e-05\n",
      "478 5.707619129680097e-05\n",
      "479 5.605887417914346e-05\n",
      "480 5.529321788344532e-05\n",
      "481 5.4711708799004555e-05\n",
      "482 5.3975891205482185e-05\n",
      "483 5.321922435541637e-05\n",
      "484 5.271731424727477e-05\n",
      "485 5.2034378313692287e-05\n",
      "486 5.141591464052908e-05\n",
      "487 5.064756260253489e-05\n",
      "488 5.02250695717521e-05\n",
      "489 4.990462912246585e-05\n",
      "490 4.9029527872335166e-05\n",
      "491 4.853141581406817e-05\n",
      "492 4.794249252881855e-05\n",
      "493 4.72753745270893e-05\n",
      "494 4.692524817073718e-05\n",
      "495 4.6334702346939594e-05\n",
      "496 4.5745837269350886e-05\n",
      "497 4.5113381929695606e-05\n",
      "498 4.4598164095077664e-05\n",
      "499 4.423217615112662e-05\n"
     ]
    }
   ],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "#随机创建一些训练数据\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "w1=torch.randn(D_in,H)\n",
    "w2=torch.randn(H,D_out)\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    # Forward pass\n",
    "    h=x.mm(w1) # N*H\n",
    "    h_relu=h.clamp(min=0) # N*H\n",
    "    y_pred=h_relu.mm(w2)# N*D_out\n",
    "    # compute loss\n",
    "    loss =(y_pred-y).pow(2).sum().item()\n",
    "    print(i,loss)\n",
    "    # Backward pass\n",
    "    # compute the gradient\n",
    "    grad_y_pred=2.0*(y_pred-y)\n",
    "    grad_w2=h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu=grad_y_pred.mm(w2.T)\n",
    "    grad_h=grad_h_relu.clone()\n",
    "    grad_h[h<0]=0\n",
    "    grad_w1=x.t().mm(grad_h)\n",
    "    # update weights of w1 and w2\n",
    "    w1-=learning_rate*grad_w1\n",
    "    w2-=learning_rate*grad_w2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "w=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(1.,requires_grad=True)\n",
    "y=w*x+b\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "w=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(1.,requires_grad=True)\n",
    "y=w*x+b\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy 转 pytorch 简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31117174.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-50451cf18d33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mw1\u001b[0m\u001b[1;33m-=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mw2\u001b[0m\u001b[1;33m-=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "#随机创建一些训练数据\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "w1=torch.randn(D_in,H,requires_grad=True)\n",
    "w2=torch.randn(H,D_out,requires_grad=True)\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    # forward pass\n",
    "    y_pred=x.mm(w1).clamp(min=0).mm(w2)\n",
    "    #loss function\n",
    "    loss=(y_pred-y).pow(2).sum()\n",
    "    print(i,loss.item())\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    w1-=learning_rate*w1.grad\n",
    "    w2-=learning_rate*w2.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "#随机创建一些训练数据\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "w1=torch.randn(D_in,H,requires_grad = True)\n",
    "w2=torch.randn(H,D_out,requires_grad = True)\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    # forward pass\n",
    "    y_pred=x.mm(w1).clamp(min=0).mm(w2)\n",
    "    #loss function\n",
    "    loss=(y_pred-y).pow(2).sum()\n",
    "    print(i,loss.item())\n",
    "    w1.retain_grad() \n",
    "    w2.retain_grad() \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    w1= w1 - learning_rate*w1.grad\n",
    "    w2= w2 - learning_rate*w2.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYTORCH NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "import torch.nn as nn\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "model=nn.Sequential(\n",
    "    nn.Linear(D_in,H),# w1*x + b1\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H,D_out)\n",
    ")\n",
    "loss_func=nn.MSELoss(reduction=\"sum\")\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    y_pre=model(x) #forward pass\n",
    "    loss=loss_func(y_pre,y)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param-=learning_rate*param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=x.dot(w1)\n",
    "h_relu=np.maximum(h,0)\n",
    "y_pred=h_relu.dot(w2)\n",
    "y_pred-y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy 转 pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "#随机创建一些训练数据\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "w1=torch.randn(D_in,H)\n",
    "w2=torch.randn(H,D_out)\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    # Forward pass\n",
    "    h=x.mm(w1) # N*H\n",
    "    h_relu=h.clamp(min=0) # N*H\n",
    "    y_pred=h_relu.mm(w2)# N*D_out\n",
    "    # compute loss\n",
    "    loss =(y_pred-y).pow(2).sum().item()\n",
    "    print(i,loss)\n",
    "    # Backward pass\n",
    "    # compute the gradient\n",
    "    grad_y_pred=2.0*(y_pred-y)\n",
    "    grad_w2=h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu=grad_y_pred.mm(w2.T)\n",
    "    grad_h=grad_h_relu.clone()\n",
    "    grad_h[h<0]=0\n",
    "    grad_w1=x.t().mm(grad_h)\n",
    "    # update weights of w1 and w2\n",
    "    w1-=learning_rate*grad_w1\n",
    "    w2-=learning_rate*grad_w2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "w=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(1.,requires_grad=True)\n",
    "y=w*x+b\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "w=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(1.,requires_grad=True)\n",
    "y=w*x+b\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy 转 pytorch 简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "#随机创建一些训练数据\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "w1=torch.randn(D_in,H,requires_grad=True)\n",
    "w2=torch.randn(H,D_out,requires_grad=True)\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    # forward pass\n",
    "    y_pred=x.mm(w1).clamp(min=0).mm(w2)\n",
    "    #loss function\n",
    "    loss=(y_pred-y).pow(2).sum()\n",
    "    print(i,loss.item())\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    w1-=learning_rate*w1.grad\n",
    "    w2-=learning_rate*w2.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "#随机创建一些训练数据\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "w1=torch.randn(D_in,H,requires_grad = True)\n",
    "w2=torch.randn(H,D_out,requires_grad = True)\n",
    "learning_rate=1e-6\n",
    "for i in range(500):\n",
    "    # forward pass\n",
    "    y_pred=x.mm(w1).clamp(min=0).mm(w2)\n",
    "    #loss function\n",
    "    loss=(y_pred-y).pow(2).sum()\n",
    "    print(i,loss.item())\n",
    "    w1.retain_grad() \n",
    "    w2.retain_grad() \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    w1= w1 - learning_rate*w1.grad\n",
    "    w2= w2 - learning_rate*w2.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYTORCH NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614.6590576171875\n",
      "261.09906005859375\n",
      "127.37405395507812\n",
      "53.66188049316406\n",
      "22.32154655456543\n",
      "10.555005073547363\n",
      "6.023226737976074\n",
      "4.736900806427002\n",
      "6.298048496246338\n",
      "16.7198486328125\n",
      "57.36656951904297\n",
      "195.819091796875\n",
      "479.5545654296875\n",
      "403.9208679199219\n",
      "88.0235595703125\n",
      "35.649288177490234\n",
      "15.908058166503906\n",
      "8.12795639038086\n",
      "4.5723161697387695\n",
      "2.7505149841308594\n",
      "1.742924451828003\n",
      "1.150965929031372\n",
      "0.7834894061088562\n",
      "0.5489516258239746\n",
      "0.39321890473365784\n",
      "0.2884063124656677\n",
      "0.2162092626094818\n",
      "0.1655402034521103\n",
      "0.12905575335025787\n",
      "0.10217001289129257\n",
      "0.08157128095626831\n",
      "0.06526350975036621\n",
      "0.052439648658037186\n",
      "0.04221130162477493\n",
      "0.034050650894641876\n",
      "0.027479641139507294\n",
      "0.022216571494936943\n",
      "0.017995666712522507\n",
      "0.014591244980692863\n",
      "0.011836189776659012\n",
      "0.009595155715942383\n",
      "0.007773635908961296\n",
      "0.006317824590951204\n",
      "0.005147810094058514\n",
      "0.004206529352813959\n",
      "0.003446870017796755\n",
      "0.002831622026860714\n",
      "0.0023313164710998535\n",
      "0.0019221378024667501\n",
      "0.001585920574143529\n",
      "0.0013082950608804822\n",
      "0.0010777388233691454\n",
      "0.0008862434187904\n",
      "0.0007273244555108249\n",
      "0.0005954027874395251\n",
      "0.00048605288611724973\n",
      "0.00039590283995494246\n",
      "0.00032181345159187913\n",
      "0.00026126758893951774\n",
      "0.00021208543330430984\n",
      "0.00017235764244105667\n",
      "0.00014042497787158936\n",
      "0.00011485462164273486\n",
      "9.440806752536446e-05\n",
      "7.805332279531285e-05\n",
      "6.49315697955899e-05\n",
      "5.4340154747478664e-05\n",
      "4.572280522552319e-05\n",
      "3.86368265026249e-05\n",
      "3.275165363447741e-05\n",
      "2.780785143841058e-05\n",
      "2.36153464356903e-05\n",
      "2.00316499103792e-05\n",
      "1.6951080397120677e-05\n",
      "1.4298791938927025e-05\n",
      "1.201383383886423e-05\n",
      "1.0048687727248762e-05\n",
      "8.366201655007899e-06\n",
      "6.932446467544651e-06\n",
      "5.7163524616044015e-06\n",
      "4.6940949687268585e-06\n",
      "3.837128133454826e-06\n",
      "3.1247882361640222e-06\n",
      "2.535121893743053e-06\n",
      "2.0511431557679316e-06\n",
      "1.6539049738639733e-06\n",
      "1.3306963637660374e-06\n",
      "1.0682974789233413e-06\n",
      "8.565240818825259e-07\n",
      "6.862203463242622e-07\n",
      "5.502001272361667e-07\n",
      "4.424525457125128e-07\n",
      "3.5754382565755805e-07\n",
      "2.91150627163006e-07\n",
      "2.3984094355000707e-07\n",
      "2.002289392066814e-07\n",
      "1.7008079566949164e-07\n",
      "1.4714113660829753e-07\n",
      "1.295443183835232e-07\n",
      "1.1601112248627032e-07\n",
      "1.0514285975204984e-07\n",
      "9.618741358963234e-08\n",
      "8.836310882998077e-08\n",
      "8.128654371830635e-08\n",
      "7.444064920036908e-08\n",
      "6.783099593121733e-08\n",
      "6.131682539489702e-08\n",
      "5.4915563652002675e-08\n",
      "4.866084779564517e-08\n",
      "4.257465491264156e-08\n",
      "3.673432402706567e-08\n",
      "3.129598624695973e-08\n",
      "2.6307299449968014e-08\n",
      "2.180349234492951e-08\n",
      "1.7770704019426375e-08\n",
      "1.429450868783988e-08\n",
      "1.1299905899875284e-08\n",
      "8.788619609845227e-09\n",
      "6.743530622799199e-09\n",
      "5.082791965094202e-09\n",
      "3.7717393652769715e-09\n",
      "2.760379480548636e-09\n",
      "2.002621846131092e-09\n",
      "1.4390961755594844e-09\n",
      "1.0486149726318672e-09\n",
      "7.763140130734314e-10\n",
      "5.991782625613951e-10\n",
      "4.857192981155833e-10\n",
      "4.255843455425179e-10\n",
      "3.9888861658177177e-10\n",
      "3.835873840785098e-10\n",
      "3.856254204848142e-10\n",
      "3.876982901385162e-10\n",
      "3.861324593401605e-10\n",
      "3.859043085086e-10\n",
      "3.794339287210846e-10\n",
      "3.70316693976136e-10\n",
      "3.4946390226053836e-10\n",
      "3.2841168673414245e-10\n",
      "3.0542660067744976e-10\n",
      "2.7589119877546864e-10\n",
      "2.507385132854978e-10\n",
      "2.25221882810267e-10\n",
      "1.962517787168494e-10\n",
      "1.729596188493332e-10\n",
      "1.506713920296221e-10\n",
      "1.2778636482302375e-10\n",
      "1.0468074324032628e-10\n",
      "8.616374280734362e-11\n",
      "7.237828392181456e-11\n",
      "5.7129502517572206e-11\n",
      "4.864020297645766e-11\n",
      "4.101191261596249e-11\n",
      "3.039297979956501e-11\n",
      "2.490244468966729e-11\n",
      "1.9716984989148756e-11\n",
      "1.536234681132065e-11\n",
      "1.1850419950887314e-11\n",
      "9.219902619150844e-12\n",
      "8.191032054016834e-12\n",
      "7.511519184433268e-12\n",
      "6.056642600643647e-12\n",
      "4.88138912971281e-12\n",
      "4.358636715440234e-12\n",
      "4.3335343993811115e-12\n",
      "4.064970582362548e-12\n",
      "4.062890648914852e-12\n",
      "4.1490188021353624e-12\n",
      "4.117335812570122e-12\n",
      "4.403429877675169e-12\n",
      "3.889005437129889e-12\n",
      "4.2460991320214525e-12\n",
      "3.931905148690795e-12\n",
      "3.651940728988112e-12\n",
      "3.412962837692768e-12\n",
      "3.348169614822427e-12\n",
      "3.654102194439179e-12\n",
      "3.6082636444695337e-12\n",
      "3.111646790926459e-12\n",
      "3.0458797376647917e-12\n",
      "3.3271614630070445e-12\n",
      "3.437595260530335e-12\n",
      "3.052014804078018e-12\n",
      "2.7467834864264296e-12\n",
      "2.7835533357445374e-12\n",
      "2.6240173228719854e-12\n",
      "2.576884235508392e-12\n",
      "2.7790406694622183e-12\n",
      "2.2661976462057254e-12\n",
      "2.333028301798601e-12\n",
      "2.1724230487435436e-12\n",
      "2.5053342646991217e-12\n",
      "2.3524927665607986e-12\n",
      "2.2037280854314556e-12\n",
      "2.0357600154230493e-12\n",
      "2.241965944491109e-12\n",
      "2.157174612549273e-12\n",
      "1.9011517620598495e-12\n",
      "2.227924875836118e-12\n",
      "2.221860282564103e-12\n",
      "2.189025002929945e-12\n",
      "2.2899345180488195e-12\n",
      "2.413396522557565e-12\n",
      "2.2045956640098785e-12\n",
      "2.1432679849636704e-12\n",
      "2.073564410454143e-12\n",
      "2.2702549475756006e-12\n",
      "2.0291088687757197e-12\n",
      "1.7487730014087433e-12\n",
      "1.9718287332798345e-12\n",
      "2.133291156572459e-12\n",
      "2.0231635377426782e-12\n",
      "1.7615247368402143e-12\n",
      "1.847523002640461e-12\n",
      "1.983057381499398e-12\n",
      "2.096454520400526e-12\n",
      "2.244053684194447e-12\n",
      "2.132993651496329e-12\n",
      "1.7851917860634003e-12\n",
      "1.8936009444497914e-12\n",
      "1.937431985676863e-12\n",
      "1.853624675626775e-12\n",
      "1.7735669703700108e-12\n",
      "1.7568247204224896e-12\n",
      "1.6984187493906955e-12\n",
      "1.7482593064194196e-12\n",
      "2.1658423752374256e-12\n",
      "1.888175163097805e-12\n",
      "2.143413484895218e-12\n",
      "1.963393423537463e-12\n",
      "2.0568568549761412e-12\n",
      "1.8511990985264903e-12\n",
      "1.7347747587395657e-12\n",
      "1.696063862272057e-12\n",
      "1.8396848714546943e-12\n",
      "1.7546454740557937e-12\n",
      "1.8562976676628207e-12\n",
      "1.6630154284907883e-12\n",
      "1.6783139548254278e-12\n",
      "1.862379391329161e-12\n",
      "1.830695751242617e-12\n",
      "1.7234228367329907e-12\n",
      "1.916700305415464e-12\n",
      "1.8316966866882556e-12\n",
      "1.7403112371333629e-12\n",
      "2.075723273819996e-12\n",
      "2.2035992822133643e-12\n",
      "1.9138464684570478e-12\n",
      "1.9315590793489434e-12\n",
      "1.8991329776146815e-12\n",
      "1.7092790941322655e-12\n",
      "1.7573014441177315e-12\n",
      "1.7573350543850785e-12\n",
      "2.0551303714366753e-12\n",
      "1.7185085819659829e-12\n",
      "2.05202391537207e-12\n",
      "1.8737040998612065e-12\n",
      "1.8642921408018598e-12\n",
      "1.707806639161813e-12\n",
      "1.99610618832613e-12\n",
      "1.646731145540925e-12\n",
      "1.5659783582713804e-12\n",
      "1.6286355944417075e-12\n",
      "1.8481696208161313e-12\n",
      "1.8516013375324825e-12\n",
      "1.850524074253901e-12\n",
      "1.876590679725232e-12\n",
      "1.9541228444414083e-12\n",
      "1.8011783470966991e-12\n",
      "1.8858673303534523e-12\n",
      "1.8056421158610392e-12\n",
      "1.8020785601605138e-12\n",
      "1.87134400857214e-12\n",
      "2.1260085705798737e-12\n",
      "1.7601621115498345e-12\n",
      "1.8786725647368385e-12\n",
      "2.166444541124024e-12\n",
      "2.22912270239628e-12\n",
      "1.9887104116267373e-12\n",
      "1.7890879749904443e-12\n",
      "2.00596722392532e-12\n",
      "2.067481168904761e-12\n",
      "2.5101888883466428e-12\n",
      "2.345135804299181e-12\n",
      "2.2892482180736362e-12\n",
      "1.9439879393734483e-12\n",
      "1.7240683707064886e-12\n",
      "1.9026496957813555e-12\n",
      "1.9711630331459284e-12\n",
      "1.798835819882827e-12\n",
      "1.9592875499102602e-12\n",
      "1.770428530341317e-12\n",
      "2.0597215339562824e-12\n",
      "2.1141898995380437e-12\n",
      "1.9123528715442317e-12\n",
      "1.9430579107498902e-12\n",
      "2.1312749742125048e-12\n",
      "1.8821745377539667e-12\n",
      "1.756553561459151e-12\n",
      "1.620852974407172e-12\n",
      "1.696504048354086e-12\n",
      "1.9007705565760036e-12\n",
      "1.8085103727083496e-12\n",
      "2.1918090172684535e-12\n",
      "1.937056418044314e-12\n",
      "2.0996626746289104e-12\n",
      "2.0413343324726663e-12\n",
      "2.046818227061098e-12\n",
      "2.1351191214352694e-12\n",
      "2.1112397854267106e-12\n",
      "1.7892271865493914e-12\n",
      "2.089436046057158e-12\n",
      "2.02327694528992e-12\n",
      "2.1574172569954753e-12\n",
      "2.3209739252044725e-12\n",
      "2.3588704774202274e-12\n",
      "2.2285068755623083e-12\n",
      "2.0426061016209918e-12\n",
      "2.1069966518044714e-12\n",
      "2.5519092047843195e-12\n",
      "2.1495624290962523e-12\n",
      "2.174148448080837e-12\n",
      "2.318589330946308e-12\n",
      "2.178627937776678e-12\n",
      "2.0034167467347652e-12\n",
      "2.2380498062440912e-12\n",
      "2.04923404634183e-12\n",
      "1.8994705981711935e-12\n",
      "1.979148182146284e-12\n",
      "2.0607458881688467e-12\n",
      "2.0114504679924483e-12\n",
      "1.846487372725303e-12\n",
      "1.9681125219134232e-12\n",
      "2.0163321966942815e-12\n",
      "1.862479788450333e-12\n",
      "2.066556344451631e-12\n",
      "2.1232783326691207e-12\n",
      "1.916790944717084e-12\n",
      "1.870153120905882e-12\n",
      "1.617346230900485e-12\n",
      "2.0270141901784777e-12\n",
      "1.9242023339277603e-12\n",
      "1.8754249455493754e-12\n",
      "2.15310343339159e-12\n",
      "1.886781095944423e-12\n",
      "2.404414124398957e-12\n",
      "2.1050346795531416e-12\n",
      "2.299858871054883e-12\n",
      "2.159716849803317e-12\n",
      "2.0563876122758895e-12\n",
      "2.215126953392099e-12\n",
      "1.9221941746638826e-12\n",
      "2.1740452320340165e-12\n",
      "2.3025960478595398e-12\n",
      "2.336914082384789e-12\n",
      "1.9909583964111688e-12\n",
      "2.100678355224095e-12\n",
      "2.223029269346477e-12\n",
      "2.1485912007901398e-12\n",
      "2.0088711510241053e-12\n",
      "1.9135157867944397e-12\n",
      "1.8424203135358752e-12\n",
      "2.0257931616918246e-12\n",
      "1.992785710752676e-12\n",
      "2.0467260698764367e-12\n",
      "1.791504878473349e-12\n",
      "1.8852571413707775e-12\n",
      "2.164777255023176e-12\n",
      "1.849092060024482e-12\n",
      "2.0466430199900243e-12\n",
      "1.94266781480823e-12\n",
      "2.148305621937907e-12\n",
      "2.2713549790998044e-12\n",
      "2.1998806856021735e-12\n",
      "1.8618182082846824e-12\n",
      "2.0451468209919943e-12\n",
      "1.9090781473024565e-12\n",
      "2.0576799812654922e-12\n",
      "2.2500122424939928e-12\n",
      "2.308534656839112e-12\n",
      "2.1163394387652135e-12\n",
      "2.1439733668970895e-12\n",
      "1.9598864631903412e-12\n",
      "2.262725597168558e-12\n",
      "2.2758594054456127e-12\n",
      "2.111546180960655e-12\n",
      "2.4899997428523557e-12\n",
      "1.9755518835401498e-12\n",
      "2.0052113181706632e-12\n",
      "2.2352625392990655e-12\n",
      "2.359573474108867e-12\n",
      "2.2848706433820087e-12\n",
      "2.317352689948371e-12\n",
      "2.5014313537186084e-12\n",
      "2.0797070662825767e-12\n",
      "2.2367752181701173e-12\n",
      "1.9743265182448066e-12\n",
      "2.2329048332547785e-12\n",
      "2.414586109181216e-12\n",
      "2.5348249974715964e-12\n",
      "2.3293988266059884e-12\n",
      "2.4220311086592394e-12\n",
      "2.36709415089853e-12\n",
      "2.427962561904473e-12\n",
      "2.192175260762319e-12\n",
      "2.3605709401075536e-12\n",
      "2.3872993425849698e-12\n",
      "2.1520704055616457e-12\n",
      "2.2968929275918315e-12\n",
      "2.444015476110728e-12\n",
      "2.0376712470127067e-12\n",
      "2.1031223637613117e-12\n",
      "2.4898674701873125e-12\n",
      "2.236349777237634e-12\n",
      "1.9923348994893564e-12\n",
      "1.93680163053378e-12\n",
      "2.2660974659249877e-12\n",
      "2.228009877286441e-12\n",
      "2.3883878815661452e-12\n",
      "2.1665440708834582e-12\n",
      "2.646495869673693e-12\n",
      "2.3664737704154337e-12\n",
      "2.3064328225075315e-12\n",
      "2.3732025459383133e-12\n",
      "2.4189615154684985e-12\n",
      "2.4883320230706385e-12\n",
      "2.7636738383907122e-12\n",
      "2.41735689625322e-12\n",
      "2.229064589159835e-12\n",
      "2.3787647199235984e-12\n",
      "2.54337371476121e-12\n",
      "2.634085224245686e-12\n",
      "2.802332801574159e-12\n",
      "2.387216509538992e-12\n",
      "1.7708431292520754e-12\n",
      "2.2342694101090688e-12\n",
      "2.2774588204904633e-12\n",
      "2.3958001381385596e-12\n",
      "2.3622909184339846e-12\n",
      "2.236819670459189e-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.418892777050763e-12\n",
      "2.6149607652847795e-12\n",
      "2.1567081887746697e-12\n",
      "2.12204971476726e-12\n",
      "2.1739073215176763e-12\n",
      "1.959377321850142e-12\n",
      "2.2415749811877106e-12\n",
      "2.151722376664278e-12\n",
      "2.526080039588763e-12\n",
      "2.502268791476636e-12\n",
      "2.5102192460074724e-12\n",
      "2.251076712186939e-12\n",
      "2.096579420490796e-12\n",
      "2.6200649722724068e-12\n",
      "2.7135036839015525e-12\n",
      "2.383341787814963e-12\n",
      "2.1489754420400686e-12\n",
      "2.043417952207749e-12\n",
      "2.2506146252210257e-12\n",
      "2.7978253394622676e-12\n",
      "2.366288155003504e-12\n",
      "2.2151178460938503e-12\n",
      "2.6058814394519514e-12\n",
      "2.440210360166173e-12\n",
      "2.18846447040677e-12\n",
      "2.3607086337834593e-12\n",
      "2.314607273207203e-12\n",
      "2.5832695357830282e-12\n",
      "2.5173630541219794e-12\n",
      "2.287553393237607e-12\n",
      "2.611903098317936e-12\n",
      "2.6727602336212852e-12\n",
      "2.599138352460395e-12\n",
      "2.4304343260173056e-12\n",
      "2.5863339248033412e-12\n",
      "2.7099329724666887e-12\n",
      "2.731679899642403e-12\n",
      "2.7323872331397325e-12\n",
      "2.6002468407615442e-12\n",
      "2.568710001649155e-12\n",
      "2.538921330119681e-12\n",
      "2.561114298069156e-12\n",
      "2.2970119729903704e-12\n",
      "2.080841358595431e-12\n",
      "2.092630322497735e-12\n",
      "2.419457646382628e-12\n",
      "2.528547250052471e-12\n",
      "2.2848749801906987e-12\n",
      "2.302191423608768e-12\n",
      "2.3154501319760934e-12\n",
      "2.463696781307423e-12\n",
      "2.4756722279833943e-12\n",
      "2.4340915567855337e-12\n",
      "2.1987433575232362e-12\n",
      "2.378494970423084e-12\n",
      "2.5819559164308448e-12\n",
      "2.2448273708647326e-12\n",
      "2.221790893625064e-12\n",
      "2.2736502350989563e-12\n",
      "2.4906697797949517e-12\n"
     ]
    }
   ],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "import torch.nn as nn\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "model=nn.Sequential(\n",
    "    nn.Linear(D_in,H,bias=False),# w1*x + b1\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H,D_out,bias=False)\n",
    ")\n",
    "loss_func=nn.MSELoss(reduction=\"sum\")\n",
    "learning_rate=1e-3\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "for i in range(500):\n",
    "    y_pre=model(x) #forward pass\n",
    "    loss=loss_func(y_pre,y)\n",
    "    print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     with torch.no_grad():\n",
    "#         for param in model.parameters():\n",
    "#             param-=learning_rate*param.grad\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用class封装模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D_in,H,D_out=64,1000,100,10\n",
    "import torch.nn as nn\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        super(TwoLayerNet,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H,bias=False)\n",
    "        self.linear2=nn.Linear(H,D_out,bias=False)\n",
    "    def forward(self,x):\n",
    "        y_pred=self.linear2(self.linear1(x).clamp(min=0))\n",
    "        return y_pred\n",
    "model=TwoLayerNet(D_in,H,D_out)\n",
    "loss_func=nn.MSELoss(reduction=\"sum\")\n",
    "learning_rate=1e-3\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "for i in range(500):\n",
    "    y_pre=model(x) #forward pass\n",
    "    loss=loss_func(y_pre,y)\n",
    "    print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param-=learning_rate*param.grad\n",
    "    model.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
